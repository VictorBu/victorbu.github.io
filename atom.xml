<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Victor Blog</title>
  
  <subtitle>户外, 旅行, 读书, 生活, 有趣</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://victor.karonda.com/"/>
  <updated>2021-05-28T02:00:00.000Z</updated>
  <id>http://victor.karonda.com/</id>
  
  <author>
    <name>Victor Bu</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>仿谷歌验证 (Google Authenticator) 的一种 Java 实现</title>
    <link href="http://victor.karonda.com/2021/05/2124-google-authenticator/"/>
    <id>http://victor.karonda.com/2021/05/2124-google-authenticator/</id>
    <published>2021-05-28T02:00:00.000Z</published>
    <updated>2021-05-28T02:00:00.000Z</updated>
    
    <content type="html"><![CDATA[<p>Google Authenticator 的原理是服务器随机生成一个密钥并保存并告知客户端。用户需要登陆时客户端根据密钥和时间戳通过一种算法生成一个6位数字的密码。本文使用 java.util.zip.CRC32 模仿 Google Authenticator 实现此功能。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line">/**</span><br><span class="line"> * 生成验证码</span><br><span class="line"> * @param secret: 密钥</span><br><span class="line"> * @param timeMinute: 时间戳（分钟）</span><br><span class="line"> * @param codeLength: 验证码长度</span><br><span class="line"> * @return 指定长度的数字</span><br><span class="line"> */</span><br><span class="line">public static String generateCode(String secret, long timeMinute, int codeLength) &#123;</span><br><span class="line">    String key = secret + timeMinute;</span><br><span class="line">    CRC32 crc32 = new CRC32();</span><br><span class="line">    crc32.update(key.getBytes());</span><br><span class="line">    String crc32ValueStr = String.valueOf(crc32.getValue());</span><br><span class="line">    return crc32ValueStr.substring(crc32ValueStr.length() - codeLength); // 可以改成其他规则</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">/***</span><br><span class="line"> * 校验验证码</span><br><span class="line"> * @param secret: 密钥</span><br><span class="line"> * @param verifyCode: 待校验验证码</span><br><span class="line"> * @param expireMinute</span><br><span class="line"> * @return</span><br><span class="line"> */</span><br><span class="line">public static boolean verifyCode(String secret, String verifyCode, int codeLength, int expireMinute) &#123;</span><br><span class="line">    long timeMillisecond = System.currentTimeMillis();</span><br><span class="line">    long timeMinute = minuteByMillisecond(timeMillisecond);</span><br><span class="line"></span><br><span class="line">    for (int i = -expireMinute; i &lt;= expireMinute; ++i) &#123;</span><br><span class="line">        String code = generateCode(secret, timeMinute + i, codeLength);</span><br><span class="line">        if(code.equals(verifyCode)) &#123;</span><br><span class="line">            return true;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    return false;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">/***</span><br><span class="line"> * 获取时间戳（分钟）</span><br><span class="line"> * @param timeMillisecond: 时间戳（毫秒）</span><br><span class="line"> * @return</span><br><span class="line"> */</span><br><span class="line">private static long minuteByMillisecond(long timeMillisecond) &#123;</span><br><span class="line">    return timeMillisecond / (1000 * 60);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>使用：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">final int CODE_LENGTH = 6;</span><br><span class="line">final int CODE_EXPIRE_MINUTE = 1;</span><br><span class="line">final String SECRET = &quot;YOUR SECRET&quot;;</span><br><span class="line"></span><br><span class="line">long timeMillisecond = System.currentTimeMillis();</span><br><span class="line">long timeMinute = minuteByMillisecond(timeMillisecond);</span><br><span class="line">String code = generateCode(SECRET, timeMinute, CODE_LENGTH);</span><br><span class="line">boolean result = verifyCode(SECRET, code, CODE_LENGTH, CODE_EXPIRE_MINUTE);</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;Google Authenticator 的原理是服务器随机生成一个密钥并保存并告知客户端。用户需要登陆时客户端根据密钥和时间戳通过一种算法生成一个6位数字的密码。本文使用 java.util.zip.CRC32 模仿 Google Authenticator 实现此功能。
      
    
    </summary>
    
      <category term="IT" scheme="http://victor.karonda.com/categories/IT/"/>
    
    
      <category term="Java" scheme="http://victor.karonda.com/tags/Java/"/>
    
      <category term="Google Authenticator" scheme="http://victor.karonda.com/tags/Google-Authenticator/"/>
    
  </entry>
  
  <entry>
    <title>k8s 部署 (二) EMQ X 集群</title>
    <link href="http://victor.karonda.com/2021/05/2123-k8s-deploy-2/"/>
    <id>http://victor.karonda.com/2021/05/2123-k8s-deploy-2/</id>
    <published>2021-05-20T02:00:00.000Z</published>
    <updated>2021-05-20T02:00:00.000Z</updated>
    
    <content type="html"><![CDATA[<p>本文部署的 EMQ X Broker 版本为 4.3.1</p><h1 id="一、RBAC-鉴权"><a href="#一、RBAC-鉴权" class="headerlink" title="一、RBAC 鉴权"></a>一、RBAC 鉴权</h1><p>集群需要使用到 Kubernetes 的 API Server，但是普通 Pod 是没有权限访问的，需要授权：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line">---</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: ServiceAccount</span><br><span class="line">metadata:</span><br><span class="line">  namespace: default</span><br><span class="line">  name: emqx</span><br><span class="line">---</span><br><span class="line">apiVersion: rbac.authorization.k8s.io/v1</span><br><span class="line">kind: Role</span><br><span class="line">metadata:</span><br><span class="line">  name: emqx</span><br><span class="line">  namespace: default</span><br><span class="line"></span><br><span class="line">rules:</span><br><span class="line">  - apiGroups:</span><br><span class="line">      - &apos;&apos;</span><br><span class="line">    resources:</span><br><span class="line">      - endpoints </span><br><span class="line">    verbs: </span><br><span class="line">      - get</span><br><span class="line">      - watch</span><br><span class="line">      - list</span><br><span class="line">---</span><br><span class="line">apiVersion: rbac.authorization.k8s.io/v1</span><br><span class="line">kind: RoleBinding</span><br><span class="line">metadata:</span><br><span class="line">  name: emqx</span><br><span class="line">  namespace: default</span><br><span class="line">roleRef:</span><br><span class="line">  kind: Role</span><br><span class="line">  name: emqx</span><br><span class="line">  apiGroup: rbac.authorization.k8s.io</span><br><span class="line">subjects:</span><br><span class="line">  - kind: ServiceAccount</span><br><span class="line">    name: emqx</span><br><span class="line">    namespace: default</span><br></pre></td></tr></table></figure><p>如果没有授权，会有如下报错：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Ekka(AutoCluster): Discovery error: &#123;403,&quot;&#123;&quot;kind&quot;:&quot;Status&quot;,&quot;apiVersion&quot;:&quot;v1&quot;,&quot;metadata&quot;:&#123;&#125;,&quot;status&quot;:&quot;Failure&quot;,&quot;message&quot;:&quot;endpoints &quot;emqx-headless&quot; is forbidden: User &quot;system:serviceaccount:default:default&quot; cannot get resource &quot;endpoints&quot; in API group &quot;&quot; in the namespace &quot;default&quot;&quot;,&quot;reason&quot;:&quot;Forbidden&quot;,&quot;details&quot;:&#123;&quot;name&quot;:&quot;emqx-headless&quot;,&quot;kind&quot;:&quot;endpoints&quot;&#125;,&quot;code&quot;:403&#125;&quot;&#125;</span><br></pre></td></tr></table></figure><h1 id="二、新增-ConfigMap"><a href="#二、新增-ConfigMap" class="headerlink" title="二、新增 ConfigMap"></a>二、新增 ConfigMap</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: v1</span><br><span class="line">kind: ConfigMap</span><br><span class="line">metadata:</span><br><span class="line">  name: emqx-cm</span><br><span class="line">data:</span><br><span class="line">  NAME: &quot;emqx&quot;</span><br><span class="line">  CLUSTER__DISCOVERY: &quot;k8s&quot;</span><br><span class="line">  CLUSTER__K8S__ADDRESS_TYPE: &quot;ip&quot;</span><br><span class="line">  CLUSTER__K8S__APISERVER: &quot;https://IP:PORT&quot;</span><br><span class="line">  CLUSTER__K8S__NAMESPACE: &quot;default&quot;</span><br><span class="line">  CLUSTER__K8S__SERVICE_NAME: &quot;emqx-headless&quot;</span><br><span class="line">  CLUSTER__K8S__APP_NAME: &quot;emqx&quot;</span><br></pre></td></tr></table></figure><p>默认情况下 EMQ X 使用带有 EMQX_ 的前缀的环境变量来覆盖配置文件中的配置项环境变量名称到配置文件键值名称映射规则如下:将 EMQX_ 前缀移除；大写字符替换成小写；双下划线 __ 替换成点 .  详见：<a href="https://docs.emqx.cn/broker/v4.3/configuration/environment-variable.html" target="_blank" rel="noopener">使用环境变量修改配置</a></p><ul><li>cluster.kubernetes.apiserver 为 kubernetes apiserver 的地址，可以通过 kubectl cluster-info 命令获取</li><li>cluster.kubernetes.service_name 为 Service 的 name</li><li>cluster.kubernetes.app_name 为 EMQ X Broker 的 node.name 中 @ 符号之前的部分，需要同时将集群中 EMQ X Broker 设置为统一的 node.name 的前缀</li></ul><h1 id="三、新增-Deployment"><a href="#三、新增-Deployment" class="headerlink" title="三、新增 Deployment"></a>三、新增 Deployment</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: apps/v1</span><br><span class="line">kind: Deployment</span><br><span class="line">metadata:</span><br><span class="line">  labels:</span><br><span class="line">    app: emqx</span><br><span class="line">  name: emqx</span><br><span class="line">  namespace: default</span><br><span class="line">spec:</span><br><span class="line">  replicas: 3</span><br><span class="line">  selector:</span><br><span class="line">    matchLabels:</span><br><span class="line">      app: emqx</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      labels:</span><br><span class="line">        app: emqx</span><br><span class="line">    spec:</span><br><span class="line">      serviceAccountName: emqx</span><br><span class="line">      containers:</span><br><span class="line">        - envFrom:</span><br><span class="line">          - prefix: EMQX_</span><br><span class="line">            configMapRef: </span><br><span class="line">              name: emqx-cm            </span><br><span class="line">          image: emqx/emqx:4.3.1</span><br><span class="line">          imagePullPolicy: IfNotPresent  </span><br><span class="line">          livenessProbe:</span><br><span class="line">            exec:</span><br><span class="line">              command:</span><br><span class="line">                - emqx_ctl</span><br><span class="line">                - status</span><br><span class="line">            failureThreshold: 3</span><br><span class="line">            initialDelaySeconds: 60</span><br><span class="line">            periodSeconds: 10</span><br><span class="line">            successThreshold: 1</span><br><span class="line">            timeoutSeconds: 1          </span><br><span class="line">          name: emqx</span><br><span class="line">          ports:</span><br><span class="line">            - name: mqtt</span><br><span class="line">              protocol: TCP</span><br><span class="line">              containerPort: 1883</span><br><span class="line">            - name: mqttssl</span><br><span class="line">              protocol: TCP</span><br><span class="line">              containerPort: 8883</span><br><span class="line">            - name: mgmt</span><br><span class="line">              protocol: TCP</span><br><span class="line">              containerPort: 8081</span><br><span class="line">            - name: websocket</span><br><span class="line">              protocol: TCP</span><br><span class="line">              containerPort: 8083</span><br><span class="line">            - name: wss</span><br><span class="line">              protocol: TCP</span><br><span class="line">              containerPort: 8084</span><br><span class="line">            - name: dashboard</span><br><span class="line">              protocol: TCP</span><br><span class="line">              containerPort: 18083  </span><br><span class="line">          resources:</span><br><span class="line">            limits:</span><br><span class="line">              cpu: &apos;2&apos;</span><br><span class="line">              memory: 2Gi</span><br><span class="line">            requests:</span><br><span class="line">              cpu: &apos;1&apos;</span><br><span class="line">              memory: 2Gi</span><br><span class="line">          volumeMounts:</span><br><span class="line">            - mountPath: /etc/localtime</span><br><span class="line">              name: volume-localtime</span><br><span class="line">      volumes:</span><br><span class="line">        - hostPath:</span><br><span class="line">            path: /etc/localtime</span><br><span class="line">            type: &apos;&apos;</span><br><span class="line">          name: volume-localtime</span><br></pre></td></tr></table></figure><ul><li>1883    MQTT 协议端口</li><li>8883    MQTT/SSL 端口</li><li>8083    MQTT/WebSocket 端口</li><li>8084    MQTT/WebSocket/SSL 端口</li><li>8081    管理 API 端口</li><li>18083    Dashboard 端口</li></ul><h1 id="四、新增-Service"><a href="#四、新增-Service" class="headerlink" title="四、新增 Service"></a>四、新增 Service</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: v1</span><br><span class="line">kind: Service</span><br><span class="line">metadata:</span><br><span class="line">  name: emqx-headless</span><br><span class="line">  labels:</span><br><span class="line">    app: emqx-headless</span><br><span class="line">spec:</span><br><span class="line">  type: ClusterIP</span><br><span class="line">  clusterIP: None</span><br><span class="line">  ports:</span><br><span class="line">    - name: mqtt</span><br><span class="line">      port: 1883</span><br><span class="line">      protocol: TCP</span><br><span class="line">      targetPort: 1883</span><br><span class="line">    - name: mqttssl</span><br><span class="line">      port: 8883</span><br><span class="line">      protocol: TCP</span><br><span class="line">      targetPort: 8883</span><br><span class="line">    - name: mgmt</span><br><span class="line">      port: 8081</span><br><span class="line">      protocol: TCP</span><br><span class="line">      targetPort: 8081</span><br><span class="line">    - name: websocket</span><br><span class="line">      port: 8083</span><br><span class="line">      protocol: TCP</span><br><span class="line">      targetPort: 8083</span><br><span class="line">    - name: wss</span><br><span class="line">      port: 8084</span><br><span class="line">      protocol: TCP</span><br><span class="line">      targetPort: 8084</span><br><span class="line">    - name: dashboard</span><br><span class="line">      port: 18083</span><br><span class="line">      protocol: TCP</span><br><span class="line">      targetPort: 18083      </span><br><span class="line">  selector:</span><br><span class="line">    app: emqx</span><br></pre></td></tr></table></figure><h1 id="五、放行-TCP-端口"><a href="#五、放行-TCP-端口" class="headerlink" title="五、放行 TCP 端口"></a>五、放行 TCP 端口</h1><p>见：<a href="https://www.cnblogs.com/victorbu/p/14780037.html" target="_blank" rel="noopener">阿里云 k8s 部署 Spring Cloud Alibaba 微服务实践 (五) Kubernetes TCP Ingress</a></p><p>参考：</p><p>1.<a href="https://zhuanlan.zhihu.com/p/148734253" target="_blank" rel="noopener">从零开始建立 EMQ X MQTT 服务器 的 K8S 集群</a></p><ol><li><a href="https://docs.emqx.cn/broker/v4.3/" target="_blank" rel="noopener">EMQ X Broker 文档</a></li></ol>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;本文部署的 EMQ X Broker 版本为 4.3.1&lt;/p&gt;
&lt;h1 id=&quot;一、RBAC-鉴权&quot;&gt;&lt;a href=&quot;#一、RBAC-鉴权&quot; class=&quot;headerlink&quot; title=&quot;一、RBAC 鉴权&quot;&gt;&lt;/a&gt;一、RBAC 鉴权&lt;/h1&gt;&lt;p&gt;集群需要使用
      
    
    </summary>
    
      <category term="IT" scheme="http://victor.karonda.com/categories/IT/"/>
    
    
      <category term="MQTT" scheme="http://victor.karonda.com/tags/MQTT/"/>
    
      <category term="Kubernetes" scheme="http://victor.karonda.com/tags/Kubernetes/"/>
    
      <category term="EMQ X" scheme="http://victor.karonda.com/tags/EMQ-X/"/>
    
  </entry>
  
  <entry>
    <title>k8s 部署 (一) SkyWalking 集群</title>
    <link href="http://victor.karonda.com/2021/05/2123-k8s-deploy-1/"/>
    <id>http://victor.karonda.com/2021/05/2123-k8s-deploy-1/</id>
    <published>2021-05-19T09:00:00.000Z</published>
    <updated>2021-05-19T09:00:00.000Z</updated>
    
    <content type="html"><![CDATA[<p>本文部署的 SkyWalking 版本为 8.5.0，集群模式为 Nacos，存储使用 Elasticsearch 7</p><p>下载对应版本的源码并解压，如本文对应的为：<a href="https://www.apache.org/dyn/closer.cgi/skywalking/8.5.0/apache-skywalking-apm-es7-8.5.0.tar.gz" target="_blank" rel="noopener">v8.5.0 for H2/MySQL/TiDB/InfluxDB/ElasticSearch 7</a></p><h1 id="一、部署-OAP-Server"><a href="#一、部署-OAP-Server" class="headerlink" title="一、部署 OAP Server"></a>一、部署 OAP Server</h1><h2 id="1-1-添加-ConfigMap"><a href="#1-1-添加-ConfigMap" class="headerlink" title="1.1. 添加 ConfigMap"></a>1.1. 添加 ConfigMap</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: v1</span><br><span class="line">kind: ConfigMap</span><br><span class="line">metadata:</span><br><span class="line">  name: skywalking-cm</span><br><span class="line">data:</span><br><span class="line">  CLUSTER: &apos;nacos&apos;</span><br><span class="line">  CLUSTER_NACOS_HOST_PORT: &apos;nacos-headless:8848&apos;</span><br><span class="line">  STORAGE: &apos;elasticsearch7&apos;</span><br><span class="line">  STORAGE_ES_CLUSTER_NODES: &apos;IP:PORT&apos;</span><br><span class="line">  ES_USER: &apos;用户名&apos;</span><br><span class="line">  ES_PASSWORD: &apos;密码&apos;</span><br><span class="line">  CORE_GRPC_PORT: &apos;11800&apos;</span><br><span class="line">  CORE_REST_PORT: &apos;12800&apos;</span><br></pre></td></tr></table></figure><p>配置项中为需要配置的环境变量，更多的环境变量配置见：config/application.yml</p><p>其中 nacos-headless:8848 为 Nacos 地址，根据需要修改；gRPC 端口为 agent 上传数据端口；rest 端口为 UI 调用端口</p><h2 id="1-2-添加-Deployment"><a href="#1-2-添加-Deployment" class="headerlink" title="1.2. 添加 Deployment"></a>1.2. 添加 Deployment</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: apps/v1</span><br><span class="line">kind: Deployment</span><br><span class="line">metadata:</span><br><span class="line">  labels:</span><br><span class="line">    app: skywalking</span><br><span class="line">  name: skywalking</span><br><span class="line">  namespace: default</span><br><span class="line">spec:</span><br><span class="line">  replicas: 2</span><br><span class="line">  selector:</span><br><span class="line">    matchLabels:</span><br><span class="line">      app: skywalking</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      labels:</span><br><span class="line">        app: skywalking</span><br><span class="line">    spec:</span><br><span class="line">      containers:</span><br><span class="line">        - envFrom:</span><br><span class="line">          - prefix: SW_</span><br><span class="line">            configMapRef: </span><br><span class="line">              name: skywalking-cm                  </span><br><span class="line">          image: apache/skywalking-oap-server:8.5.0-es7</span><br><span class="line">          imagePullPolicy: IfNotPresent         </span><br><span class="line">          name: skywalking</span><br><span class="line">          ports:</span><br><span class="line">            - containerPort: 12800</span><br><span class="line">              name: http</span><br><span class="line">              protocol: TCP</span><br><span class="line">            - containerPort: 11800</span><br><span class="line">              name: grpc</span><br><span class="line">              protocol: TCP</span><br><span class="line">          resources:</span><br><span class="line">            limits:</span><br><span class="line">              cpu: &apos;2&apos;</span><br><span class="line">              memory: 2Gi</span><br><span class="line">            requests:</span><br><span class="line">              cpu: &apos;1&apos;</span><br><span class="line">              memory: 2Gi</span><br><span class="line">          volumeMounts:</span><br><span class="line">            - mountPath: /etc/localtime</span><br><span class="line">              name: volume-localtime</span><br><span class="line">      volumes:</span><br><span class="line">        - hostPath:</span><br><span class="line">            path: /etc/localtime</span><br><span class="line">            type: &apos;&apos;</span><br><span class="line">          name: volume-localtime</span><br></pre></td></tr></table></figure><h2 id="1-3-添加-Service"><a href="#1-3-添加-Service" class="headerlink" title="1.3. 添加 Service"></a>1.3. 添加 Service</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: v1</span><br><span class="line">kind: Service</span><br><span class="line">metadata:</span><br><span class="line">  name: skywalking</span><br><span class="line">  labels:</span><br><span class="line">    app: skywalking</span><br><span class="line">spec:</span><br><span class="line">  type: ClusterIP</span><br><span class="line">  ports:</span><br><span class="line">    - name: http</span><br><span class="line">      port: 12800</span><br><span class="line">      protocol: TCP</span><br><span class="line">      targetPort: 12800</span><br><span class="line">    - name: grpc</span><br><span class="line">      port: 11800</span><br><span class="line">      protocol: TCP</span><br><span class="line">      targetPort: 11800</span><br><span class="line">  selector:</span><br><span class="line">    app: skywalking</span><br></pre></td></tr></table></figure><h1 id="二、部署-UI"><a href="#二、部署-UI" class="headerlink" title="二、部署 UI"></a>二、部署 UI</h1><h2 id="2-1-添加-Deployment"><a href="#2-1-添加-Deployment" class="headerlink" title="2.1. 添加 Deployment"></a>2.1. 添加 Deployment</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: apps/v1</span><br><span class="line">kind: Deployment</span><br><span class="line">metadata:</span><br><span class="line">  labels:</span><br><span class="line">    app: skywalking-ui</span><br><span class="line">  name: skywalking-ui</span><br><span class="line">  namespace: default</span><br><span class="line">spec:</span><br><span class="line">  replicas: 1</span><br><span class="line">  selector:</span><br><span class="line">    matchLabels:</span><br><span class="line">      app: skywalking-ui</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      labels:</span><br><span class="line">        app: skywalking-ui</span><br><span class="line">    spec:</span><br><span class="line">      containers:</span><br><span class="line">        - env:</span><br><span class="line">            - name: SW_OAP_ADDRESS</span><br><span class="line">              value: &quot;skywalking:12800&quot;          </span><br><span class="line">          image: apache/skywalking-ui:8.5.0</span><br><span class="line">          imagePullPolicy: IfNotPresent         </span><br><span class="line">          name: skywalking-ui</span><br><span class="line">          ports:</span><br><span class="line">            - containerPort: 8080</span><br><span class="line">              name: http</span><br><span class="line">              protocol: TCP</span><br><span class="line">          resources:</span><br><span class="line">            limits:</span><br><span class="line">              cpu: &apos;2&apos;</span><br><span class="line">              memory: 1Gi</span><br><span class="line">            requests:</span><br><span class="line">              cpu: &apos;1&apos;</span><br><span class="line">              memory: 1Gi</span><br><span class="line">          volumeMounts:</span><br><span class="line">            - mountPath: /etc/localtime</span><br><span class="line">              name: volume-localtime</span><br><span class="line">      volumes:</span><br><span class="line">        - hostPath:</span><br><span class="line">            path: /etc/localtime</span><br><span class="line">            type: &apos;&apos;</span><br><span class="line">          name: volume-localtime</span><br></pre></td></tr></table></figure><p>更多环境变量配置见：<a href="https://hub.docker.com/r/apache/skywalking-ui" target="_blank" rel="noopener">https://hub.docker.com/r/apache/skywalking-ui</a></p><h2 id="2-2-添加-Service"><a href="#2-2-添加-Service" class="headerlink" title="2.2. 添加 Service"></a>2.2. 添加 Service</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: v1</span><br><span class="line">kind: Service</span><br><span class="line">metadata:</span><br><span class="line">  name: skywalking-ui</span><br><span class="line">  labels:</span><br><span class="line">    app: skywalking-ui</span><br><span class="line">spec:</span><br><span class="line">  type: ClusterIP</span><br><span class="line">  ports:</span><br><span class="line">    - name: http</span><br><span class="line">      port: 8080</span><br><span class="line">      protocol: TCP</span><br><span class="line">      targetPort: 8080</span><br><span class="line">  selector:</span><br><span class="line">    app: skywalking-ui</span><br></pre></td></tr></table></figure><h1 id="三、程序改造"><a href="#三、程序改造" class="headerlink" title="三、程序改造"></a>三、程序改造</h1><p>有两种设置 agent 的方法：</p><ol><li>将 agent 与程序打包在同一镜像中：实现简单</li><li>使用 Kubernetes 的 Sidecar：更加灵活</li></ol><p>本文使用第一种方法：</p><ol><li>修改 Dockerfile：</li></ol><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">FROM 基础镜像</span><br><span class="line">MAINTAINER VictorBu &lt;VictorBu.xx@gmail.com&gt;</span><br><span class="line"></span><br><span class="line">ADD agent /agent</span><br><span class="line">ADD *.jar /app.jar</span><br><span class="line">ENTRYPOINT [&quot;java&quot;, &quot;-javaagent:/agent/skywalking-agent.jar&quot;, &quot;-jar&quot;, &quot;-server&quot;, &quot;/app.jar&quot;]</span><br></pre></td></tr></table></figure><ol start="2"><li>部署时需要添加环境变量：</li></ol><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">SW_AGENT_NAME: 对应程序的名字</span><br><span class="line">SW_AGENT_COLLECTOR_BACKEND_SERVICES: skywalking:11800</span><br></pre></td></tr></table></figure><p>更多的环境变量配置见：agent/config/agent.config</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;本文部署的 SkyWalking 版本为 8.5.0，集群模式为 Nacos，存储使用 Elasticsearch 7&lt;/p&gt;
&lt;p&gt;下载对应版本的源码并解压，如本文对应的为：&lt;a href=&quot;https://www.apache.org/dyn/closer.cgi/sk
      
    
    </summary>
    
      <category term="IT" scheme="http://victor.karonda.com/categories/IT/"/>
    
    
      <category term="Elasticsearch" scheme="http://victor.karonda.com/tags/Elasticsearch/"/>
    
      <category term="Nacos" scheme="http://victor.karonda.com/tags/Nacos/"/>
    
      <category term="SkyWalking" scheme="http://victor.karonda.com/tags/SkyWalking/"/>
    
      <category term="Kubernetes" scheme="http://victor.karonda.com/tags/Kubernetes/"/>
    
  </entry>
  
  <entry>
    <title>阿里云 k8s 部署 Spring Cloud Alibaba 微服务实践 (五) Kubernetes TCP Ingress</title>
    <link href="http://victor.karonda.com/2021/05/2121-alibaba-cloud-k8s-spring-cloud-alibaba-5/"/>
    <id>http://victor.karonda.com/2021/05/2121-alibaba-cloud-k8s-spring-cloud-alibaba-5/</id>
    <published>2021-05-18T02:00:00.000Z</published>
    <updated>2021-05-18T02:00:00.000Z</updated>
    
    <content type="html"><![CDATA[<p>在 Kuberetes 应用中，一般是通过 Ingress 暴露 HTTP/HTTPS 的服务，但实际使用中可能需要暴露 TCP 服务。Ingress 默认包含了 Nginx，Nginx 本身支持 TCP 做反向代理，所以也 可以通过 Ingress 暴露 TCP 服务。</p><p>假设我们需要将服务 test-tcp 的 8081 端口暴露为 18081 端口：</p><h1 id="一、修改配置项：tcp-services"><a href="#一、修改配置项：tcp-services" class="headerlink" title="一、修改配置项：tcp-services"></a>一、修改配置项：tcp-services</h1><p>切换到 kube-system 命名空间，选中 tcp-services 配置项，添加配置：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">18081 default/test-tcp:8081</span><br></pre></td></tr></table></figure><p>其中配置项的格式为：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&lt;Nginx port&gt;: &lt;namespace/service name&gt;:&lt;service port&gt;:[PROXY]:[PROXY]</span><br></pre></td></tr></table></figure><h1 id="二、修改服务：nginx-ingress-lb"><a href="#二、修改服务：nginx-ingress-lb" class="headerlink" title="二、修改服务：nginx-ingress-lb"></a>二、修改服务：nginx-ingress-lb</h1><p>切换到 kube-system 命名空间，选中 nginx-ingress-lb 服务，添加端口映射：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">服务端口：18081 # 需要暴露的端口</span><br><span class="line">容器端口：18081 # 第一步配置的端口，也可以配置成其他端口，只要与第一步保持一致即可</span><br></pre></td></tr></table></figure><p>参考：</p><ol><li><a href="https://developer.aliyun.com/article/603225" target="_blank" rel="noopener">玩转Kubernetes TCP Ingress</a></li><li><a href="https://kubernetes.github.io/ingress-nginx/user-guide/exposing-tcp-udp-services" target="_blank" rel="noopener">Exposing TCP and UDP services</a></li></ol>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;在 Kuberetes 应用中，一般是通过 Ingress 暴露 HTTP/HTTPS 的服务，但实际使用中可能需要暴露 TCP 服务。Ingress 默认包含了 Nginx，Nginx 本身支持 TCP 做反向代理，所以也 可以通过 Ingress 暴露 TCP 服务。&lt;
      
    
    </summary>
    
      <category term="IT" scheme="http://victor.karonda.com/categories/IT/"/>
    
    
      <category term="Alibaba" scheme="http://victor.karonda.com/tags/Alibaba/"/>
    
      <category term="Kubernetes" scheme="http://victor.karonda.com/tags/Kubernetes/"/>
    
      <category term="Alibaba Cloud" scheme="http://victor.karonda.com/tags/Alibaba-Cloud/"/>
    
  </entry>
  
  <entry>
    <title>Jenkins 之权限 (Role-based Authorization Strategy)</title>
    <link href="http://victor.karonda.com/2021/03/2122-jenkins-2/"/>
    <id>http://victor.karonda.com/2021/03/2122-jenkins-2/</id>
    <published>2021-03-31T03:00:00.000Z</published>
    <updated>2021-03-31T03:00:00.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="一、配置"><a href="#一、配置" class="headerlink" title="一、配置"></a>一、配置</h1><h2 id="1-1-安装插件"><a href="#1-1-安装插件" class="headerlink" title="1.1. 安装插件"></a>1.1. 安装插件</h2><p>安装 Role-based Authorization Strategy 插件</p><h2 id="1-2-设置授权策略"><a href="#1-2-设置授权策略" class="headerlink" title="1.2. 设置授权策略"></a>1.2. 设置授权策略</h2><p>“系统管理”–“全局安全配置”：</p><p><img src="https://victorblog.nos-eastchina1.126.net/2122/2/setting.png" alt></p><h2 id="1-3-添加用户"><a href="#1-3-添加用户" class="headerlink" title="1.3. 添加用户"></a>1.3. 添加用户</h2><p>“系统管理”–“管理用户”</p><h1 id="二、设置所有-item-权限"><a href="#二、设置所有-item-权限" class="headerlink" title="二、设置所有 item 权限"></a>二、设置所有 item 权限</h1><p>Global role 为全局权限，比如设置对所有任务均有执行权限，则按照下面设置：</p><h2 id="2-1-角色授权"><a href="#2-1-角色授权" class="headerlink" title="2.1. 角色授权"></a>2.1. 角色授权</h2><p>“系统管理”– “Manage and Assign Roles”–“Manage Roles”：</p><p><img src="https://victorblog.nos-eastchina1.126.net/2122/2/global-role.png" alt></p><h2 id="2-2-分配角色（用户绑定角色）"><a href="#2-2-分配角色（用户绑定角色）" class="headerlink" title="2.2. 分配角色（用户绑定角色）"></a>2.2. 分配角色（用户绑定角色）</h2><p>“系统管理”– “Manage and Assign Roles”–“Assign Roles”：</p><p><img src="https://victorblog.nos-eastchina1.126.net/2122/2/global-role-assign.png" alt></p><p>注：需要勾选“全部” 的 Read 权限</p><h1 id="三、设置部分-item-权限"><a href="#三、设置部分-item-权限" class="headerlink" title="三、设置部分 item 权限"></a>三、设置部分 item 权限</h1><p>Item role 为任务权限，比如设置对所有任务名包含 “demo” 的任务均有执行权限，则按照下面设置：</p><h2 id="3-1-角色授权"><a href="#3-1-角色授权" class="headerlink" title="3.1. 角色授权"></a>3.1. 角色授权</h2><p>“系统管理”– “Manage and Assign Roles”–“Manage Roles”：</p><p><img src="https://victorblog.nos-eastchina1.126.net/2122/2/item-role.png" alt></p><h2 id="3-2-分配角色（用户绑定角色）"><a href="#3-2-分配角色（用户绑定角色）" class="headerlink" title="3.2. 分配角色（用户绑定角色）"></a>3.2. 分配角色（用户绑定角色）</h2><p>“系统管理”– “Manage and Assign Roles”–“Assign Roles”：</p><p><img src="https://victorblog.nos-eastchina1.126.net/2122/2/item-role-assign.png" alt></p><p>注：同样需要设置 Global role 的权限：勾选“全部” 的 Read 权限</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;一、配置&quot;&gt;&lt;a href=&quot;#一、配置&quot; class=&quot;headerlink&quot; title=&quot;一、配置&quot;&gt;&lt;/a&gt;一、配置&lt;/h1&gt;&lt;h2 id=&quot;1-1-安装插件&quot;&gt;&lt;a href=&quot;#1-1-安装插件&quot; class=&quot;headerlink&quot; title=&quot;1
      
    
    </summary>
    
      <category term="IT" scheme="http://victor.karonda.com/categories/IT/"/>
    
    
      <category term="Jenkins" scheme="http://victor.karonda.com/tags/Jenkins/"/>
    
  </entry>
  
  <entry>
    <title>Jenkins 之使用自定义主题</title>
    <link href="http://victor.karonda.com/2021/03/2122-jenkins-1/"/>
    <id>http://victor.karonda.com/2021/03/2122-jenkins-1/</id>
    <published>2021-03-30T12:00:00.000Z</published>
    <updated>2021-03-30T12:00:00.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="一、下载主题"><a href="#一、下载主题" class="headerlink" title="一、下载主题"></a>一、下载主题</h1><p>打开：<a href="http://afonsof.com/jenkins-material-theme/" target="_blank" rel="noopener">http://afonsof.com/jenkins-material-theme</a></p><p>选择主题颜色、上传 logo，然后下载主题：</p><p><img src="https://victorblog.nos-eastchina1.126.net/2122/1/download.png" alt></p><h1 id="二、配置-Jenkins"><a href="#二、配置-Jenkins" class="headerlink" title="二、配置 Jenkins"></a>二、配置 Jenkins</h1><ol><li>安装 Simple Theme 插件</li><li>系统管理–系统配置–Theme–Extra CSS</li><li>将第一步下载的文件中的内容拷贝粘贴后保存即可</li></ol><p>参考：</p><p><a href="http://afonsof.com/jenkins-material-theme/" target="_blank" rel="noopener">jenkins-material-theme</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;一、下载主题&quot;&gt;&lt;a href=&quot;#一、下载主题&quot; class=&quot;headerlink&quot; title=&quot;一、下载主题&quot;&gt;&lt;/a&gt;一、下载主题&lt;/h1&gt;&lt;p&gt;打开：&lt;a href=&quot;http://afonsof.com/jenkins-material-theme/
      
    
    </summary>
    
      <category term="IT" scheme="http://victor.karonda.com/categories/IT/"/>
    
    
      <category term="Jenkins" scheme="http://victor.karonda.com/tags/Jenkins/"/>
    
  </entry>
  
  <entry>
    <title>阿里云 k8s 部署 Spring Cloud Alibaba 微服务实践 (四) 自动化部署</title>
    <link href="http://victor.karonda.com/2021/03/2121-alibaba-cloud-k8s-spring-cloud-alibaba-4/"/>
    <id>http://victor.karonda.com/2021/03/2121-alibaba-cloud-k8s-spring-cloud-alibaba-4/</id>
    <published>2021-03-30T02:00:00.000Z</published>
    <updated>2021-05-08T11:00:00.000Z</updated>
    
    <content type="html"><![CDATA[<p>本文使用操作系统为 CentOS 7，Jenkins 版本为 2.277.1</p><h1 id="零、准备工作"><a href="#零、准备工作" class="headerlink" title="零、准备工作"></a>零、准备工作</h1><h2 id="0-1-安装-JDK"><a href="#0-1-安装-JDK" class="headerlink" title="0.1. 安装 JDK"></a>0.1. 安装 JDK</h2><p>本文使用 rpm 安装：<a href="https://download.oracle.com/otn-pub/java/jdk/8u281-b09/89d678f2be164786b292527658ca1605/jdk-8u281-linux-x64.rpm" target="_blank" rel="noopener">下载 rpm 包</a></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">rpm -ivh jdk-8u281-linux-x64.rpm</span><br></pre></td></tr></table></figure><p>注：</p><ol><li>无需配置环境变量</li><li>默认下载链接需要登录，将链接中的 otn 改为 otn-pub 即可免登录下载，见：<a href="https://blog.csdn.net/qq_52859790/article/details/113740195" target="_blank" rel="noopener">Oracle 免登录下载 JDK</a></li></ol><h2 id="0-2-安装配置-Maven"><a href="#0-2-安装配置-Maven" class="headerlink" title="0.2. 安装配置 Maven"></a>0.2. 安装配置 Maven</h2><p>本文 Maven 安装在：/usr/local/maven，下载 Maven：<a href="https://mirrors.tuna.tsinghua.edu.cn/apache/maven/maven-3/3.6.3/binaries/apache-maven-3.6.3-bin.tar.gz" target="_blank" rel="noopener">下载链接</a></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tar -zxvf  apache-maven-3.6.3-bin.tar.gz</span><br></pre></td></tr></table></figure><p>添加环境变量：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"># vi /etc/profile</span><br><span class="line"></span><br><span class="line">MAVEN_HOME=/usr/local/maven/apache-maven-3.6.3</span><br><span class="line">export PATH=$&#123;MAVEN_HOME&#125;/bin:$&#123;PATH&#125;</span><br><span class="line"></span><br><span class="line"># source /etc/profile</span><br><span class="line"># mvn -v</span><br></pre></td></tr></table></figure><p>注：根据实际情况决定是否替换 Maven 源、指定包下载位置等</p><h2 id="0-3-安装-Git"><a href="#0-3-安装-Git" class="headerlink" title="0.3. 安装 Git"></a>0.3. 安装 Git</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yum install -y git</span><br></pre></td></tr></table></figure><h2 id="0-4-安装配置-Docker"><a href="#0-4-安装配置-Docker" class="headerlink" title="0.4. 安装配置 Docker"></a>0.4. 安装配置 Docker</h2><p>本文使用阿里云镜像：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">curl -fsSL https://get.docker.com | bash -s docker --mirror Aliyun</span><br><span class="line"></span><br><span class="line">systemctl start docker</span><br><span class="line"></span><br><span class="line">systemctl enable docker</span><br></pre></td></tr></table></figure><p>注：需登录阿里云容器镜像服务</p><h2 id="0-5-安装配置-kubectl"><a href="#0-5-安装配置-kubectl" class="headerlink" title="0.5 安装配置 kubectl"></a>0.5 安装配置 kubectl</h2><p>本文使用阿里云地址：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">curl -Lo kubectl http://kubernetes.oss-cn-hangzhou.aliyuncs.com/kubernetes-release/release/v1.20.0/bin/linux/amd64/kubectl &amp;&amp; chmod +x ./kubectl &amp;&amp; mv ./kubectl /usr/local/bin/kubectl</span><br></pre></td></tr></table></figure><p>如果需要在集群外的服务器执行 kubectl 命令，需要先进行连接 Kubernetes 集群配置：</p><p><img src="https://victorblog.nos-eastchina1.126.net/2121/1/kubectl.png" alt></p><h1 id="一、安装配置-Jenkins"><a href="#一、安装配置-Jenkins" class="headerlink" title="一、安装配置 Jenkins"></a>一、安装配置 Jenkins</h1><h2 id="1-1-方法一（本文使用）"><a href="#1-1-方法一（本文使用）" class="headerlink" title="1.1. 方法一（本文使用）"></a>1.1. 方法一（本文使用）</h2><p>使用清华大学 Jenkins 镜像：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">curl -Lo jenkins-2.277.1-1.1.noarch.rpm https://mirrors.tuna.tsinghua.edu.cn/jenkins/redhat-stable/jenkins-2.277.1-1.1.noarch.rpm</span><br><span class="line"></span><br><span class="line">rpm -ivh jenkins-2.277.1-1.1.noarch.rpm</span><br><span class="line"></span><br><span class="line">systemctl start jenkins</span><br><span class="line"></span><br><span class="line">systemctl enable jenkins</span><br></pre></td></tr></table></figure><h2 id="1-2-方法二（未实际测试）"><a href="#1-2-方法二（未实际测试）" class="headerlink" title="1.2. 方法二（未实际测试）"></a>1.2. 方法二（未实际测试）</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">curl -Lo /etc/yum.repos.d/jenkins.repo https://pkg.jenkins.io/redhat-stable/jenkins.repo</span><br><span class="line"></span><br><span class="line">rpm --import https://pkg.jenkins.io/redhat-stable/jenkins.io.key</span><br><span class="line"></span><br><span class="line">yum install jenkins</span><br><span class="line"></span><br><span class="line">systemctl start jenkins</span><br><span class="line"></span><br><span class="line">systemctl enable jenkins</span><br></pre></td></tr></table></figure><h2 id="1-3-初始化"><a href="#1-3-初始化" class="headerlink" title="1.3. 初始化"></a>1.3. 初始化</h2><p>Jenkins 默认端口为 8080（记得放行），可以根据需要修改，亦可修改其他配置，详见：<a href="https://blog.csdn.net/qiuyeyijian/article/details/104570642" target="_blank" rel="noopener">Jenkins 使用国内镜像快速安装（rpm 安装）</a></p><ol><li>访问：IP:8080，第一次访问需要输入密码，查看密码：<figure class="highlight plain"><figcaption><span>/var/lib/jenkins/secrets/initialAdminPassword```</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">1. 设置管理员账号</span><br><span class="line">1. 安装默认插件</span><br><span class="line"></span><br><span class="line">## 1.4. 配置</span><br><span class="line"></span><br><span class="line">因为实际测试中 Maven Integration 使用有问题，所以未使用该插件，因此不需要配置 Maven，只需配置 JDK 和 Git 即可：“系统管理”--“全局工具配置”</span><br><span class="line"></span><br><span class="line">![](https://victorblog.nos-eastchina1.126.net/2121/4/jdk.png)</span><br><span class="line"></span><br><span class="line">![](https://victorblog.nos-eastchina1.126.net/2121/4/git.png)</span><br><span class="line"></span><br><span class="line">注：因 Jenkins 默认执行用户为 jenkins，会有一些权限问题，所以本文修改执行用户为 root：</span><br></pre></td></tr></table></figure></li></ol><h1 id="vi-etc-sysconfig-jenkins"><a href="#vi-etc-sysconfig-jenkins" class="headerlink" title="vi /etc/sysconfig/jenkins"></a>vi /etc/sysconfig/jenkins</h1><p>JENKINS_USER=”root”</p><h1 id="systemctl-restart-jenkins"><a href="#systemctl-restart-jenkins" class="headerlink" title="systemctl restart jenkins"></a>systemctl restart jenkins</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"></span><br><span class="line"># 二、使用 Jenkins 自动化部署</span><br><span class="line"></span><br><span class="line">## 2.1. 常规部署（适用于测试环境）</span><br><span class="line"></span><br><span class="line">1. 新建任务</span><br><span class="line">1. 构建一个自由风格的软件项目</span><br><span class="line">1. 配置项目 Git 地址、认证、分支等</span><br><span class="line">1. “构建”--“执行 shell”：</span><br></pre></td></tr></table></figure><h2 id="0-删除自己构建的包，防止有更新没有获取到"><a href="#0-删除自己构建的包，防止有更新没有获取到" class="headerlink" title="0.删除自己构建的包，防止有更新没有获取到"></a>0.删除自己构建的包，防止有更新没有获取到</h2><h2 id="rm-rf-usr-local-maven-repository-com-YOUR-COMPANY"><a href="#rm-rf-usr-local-maven-repository-com-YOUR-COMPANY" class="headerlink" title="rm -rf /usr/local/maven/repository/com/YOUR_COMPANY/*"></a>rm -rf /usr/local/maven/repository/com/YOUR_COMPANY/*</h2><h2 id="1-打包项目"><a href="#1-打包项目" class="headerlink" title="1.打包项目"></a>1.打包项目</h2><p>/usr/local/maven/apache-maven-3.6.3/bin/mvn clean package -Dmaven.test.skip=true</p><h2 id="2-添加-docker-相关文件"><a href="#2-添加-docker-相关文件" class="headerlink" title="2.添加 docker 相关文件"></a>2.添加 docker 相关文件</h2><p>targetDir=”/var/project/$JOB_BASE_NAME”<br>if [ ! -d “$targetDir” ]; then<br>        mkdir $targetDir<br>fi</p><p>cp -f ./target/*.jar $targetDir/</p><p>cp -f /var/project/Dockerfile $targetDir/</p><p>cd $targetDir</p><h1 id="3-构建镜像、推送"><a href="#3-构建镜像、推送" class="headerlink" title="3.构建镜像、推送"></a>3.构建镜像、推送</h1><p>docker build -t registry.cn-shenzhen.aliyuncs.com/YOUR_NAMESPACE/$JOB_BASE_NAME:latest .<br>docker push registry.cn-shenzhen.aliyuncs.com/YOUR_NAMESPACE/$JOB_BASE_NAME:latest</p><h1 id="4-升级"><a href="#4-升级" class="headerlink" title="4.升级"></a>4.升级</h1><p>##kubectl set image deployment $JOB_BASE_NAME $JOB_BASE_NAME=registry.cn-shenzhen.aliyuncs.com/YOUR_NAMESPACE/$JOB_BASE_NAME:latest<br>/usr/local/bin/kubectl rollout restart deployment $JOB_BASE_NAME ## 2021/05/08<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">## 2.2. 通过 tag 标签部署（适用于生产环境）</span><br><span class="line"></span><br><span class="line">1. 安装 Git Parameter 插件</span><br><span class="line">2. 新建任务</span><br><span class="line">3. 构建一个自由风格的软件项目</span><br><span class="line">4. 配置：</span><br><span class="line"></span><br><span class="line">![](https://victorblog.nos-eastchina1.126.net/2121/4/tag.png)</span><br><span class="line"></span><br><span class="line">![](https://victorblog.nos-eastchina1.126.net/2121/4/git-tag.png)</span><br><span class="line"></span><br><span class="line">5. “构建”--“执行 shell”：</span><br></pre></td></tr></table></figure></p><h2 id="如果是回滚，不需要打包、构建镜像等操作，直接执行升级命令"><a href="#如果是回滚，不需要打包、构建镜像等操作，直接执行升级命令" class="headerlink" title="如果是回滚，不需要打包、构建镜像等操作，直接执行升级命令"></a>如果是回滚，不需要打包、构建镜像等操作，直接执行升级命令</h2><p>if [ $ROLLBACK -eq 0 ]; then</p><h2 id="0-删除自己构建的包，防止有更新没有获取到-1"><a href="#0-删除自己构建的包，防止有更新没有获取到-1" class="headerlink" title="0.删除自己构建的包，防止有更新没有获取到"></a>0.删除自己构建的包，防止有更新没有获取到</h2><h2 id="rm-rf-usr-local-maven-repository-com-YOUR-COMPANY-1"><a href="#rm-rf-usr-local-maven-repository-com-YOUR-COMPANY-1" class="headerlink" title="rm -rf /usr/local/maven/repository/com/YOUR_COMPANY/*"></a>rm -rf /usr/local/maven/repository/com/YOUR_COMPANY/*</h2><h2 id="1-打包项目-1"><a href="#1-打包项目-1" class="headerlink" title="1.打包项目"></a>1.打包项目</h2><p>/usr/local/maven/apache-maven-3.6.3/bin/mvn clean package -Dmaven.test.skip=true</p><h2 id="2-添加-docker-相关文件-1"><a href="#2-添加-docker-相关文件-1" class="headerlink" title="2.添加 docker 相关文件"></a>2.添加 docker 相关文件</h2><p>targetDir=”/var/project/$JOB_BASE_NAME”<br>if [ ! -d “$targetDir” ]; then<br>        mkdir $targetDir<br>fi</p><p>cp -f ./target/*.jar $targetDir/</p><p>cp -f /var/project/Dockerfile $targetDir/</p><p>cd $targetDir</p><h1 id="3-构建镜像、推送-1"><a href="#3-构建镜像、推送-1" class="headerlink" title="3.构建镜像、推送"></a>3.构建镜像、推送</h1><p>docker build -t registry.cn-shenzhen.aliyuncs.com/YOUR_NAMESPACE/$JOB_BASE_NAME:$TAG .<br>docker push registry.cn-shenzhen.aliyuncs.com/YOUR_NAMESPACE/$JOB_BASE_NAME:$TAG</p><p>fi</p><h1 id="4-升级-1"><a href="#4-升级-1" class="headerlink" title="4.升级"></a>4.升级</h1><p>kubectl set image deployment $JOB_BASE_NAME $JOB_BASE_NAME=registry.cn-shenzhen.aliyuncs.com/YOUR_NAMESPACE/$JOB_BASE_NAME:$TAG<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">*以下内容 2021/05/08 更新*</span><br><span class="line"></span><br><span class="line">## 2.3. 部署前端(Vue.js)项目（常规部署）</span><br><span class="line"></span><br><span class="line">如果没有 Node.js 则需安装 Node.js 和 cnpm ：</span><br></pre></td></tr></table></figure></p><p>cd /usr/local/<br>tar -xvf node-v14.16.1-linux-x64.tar.xz<br>mv node-v14.16.1-linux-x64/ nodejs</p><p>ln -s /usr/local/nodejs/bin/npm /usr/bin/npm<br>ln -s /usr/local/nodejs/bin/node /usr/bin/node</p><p>npm install cnpm -g –registry=<a href="https://registry.npm.taobao.org" target="_blank" rel="noopener">https://registry.npm.taobao.org</a><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">部署脚本：</span><br></pre></td></tr></table></figure></p><h2 id="1-打包项目-2"><a href="#1-打包项目-2" class="headerlink" title="1.打包项目"></a>1.打包项目</h2><p>/usr/local/nodejs/bin/cnpm i<br>/usr/local/nodejs/bin/npm run build</p><h2 id="2-添加-docker-相关文件-2"><a href="#2-添加-docker-相关文件-2" class="headerlink" title="2.添加 docker 相关文件"></a>2.添加 docker 相关文件</h2><p>targetDir=”/var/project/$JOB_BASE_NAME”<br>if [ ! -d “$targetDir” ]; then<br>        mkdir $targetDir<br>fi</p><p>rm -rf $targetDir/*<br>cp -f /var/project/Dockerfile $targetDir/<br>cp -rf dist $targetDir/dist</p><h2 id="如果是公众号项目需要拷贝公众号的-txt-文件"><a href="#如果是公众号项目需要拷贝公众号的-txt-文件" class="headerlink" title="如果是公众号项目需要拷贝公众号的 txt 文件"></a>如果是公众号项目需要拷贝公众号的 txt 文件</h2><h2 id="cp-var-project-XXXXXXXXX-txt-targetDir-dist-XXXXXXXXX-txt"><a href="#cp-var-project-XXXXXXXXX-txt-targetDir-dist-XXXXXXXXX-txt" class="headerlink" title="cp /var/project/XXXXXXXXX.txt  $targetDir/dist/XXXXXXXXX.txt"></a>cp /var/project/XXXXXXXXX.txt  $targetDir/dist/XXXXXXXXX.txt</h2><p>cd $targetDir</p><h1 id="3-构建镜像、推送-2"><a href="#3-构建镜像、推送-2" class="headerlink" title="3.构建镜像、推送"></a>3.构建镜像、推送</h1><p>docker build -t registry.cn-shenzhen.aliyuncs.com/YOUR_NAMESPACE/$JOB_BASE_NAME:latest .<br>docker push registry.cn-shenzhen.aliyuncs.com/YOUR_NAMESPACE/$JOB_BASE_NAME:latest</p><h1 id="4-升级-2"><a href="#4-升级-2" class="headerlink" title="4.升级"></a>4.升级</h1><p>/usr/local/bin/kubectl rollout restart deployment $JOB_BASE_NAME<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">其中 Dockerfile 内容：</span><br></pre></td></tr></table></figure></p><p>FROM nginx:alpine<br>MAINTAINER VictorBu <a href="mailto:&#x56;&#105;&#99;&#x74;&#x6f;&#x72;&#66;&#x75;&#x2e;&#x78;&#120;&#x40;&#103;&#109;&#x61;&#105;&#108;&#x2e;&#x63;&#x6f;&#x6d;" target="_blank" rel="noopener">&#x56;&#105;&#99;&#x74;&#x6f;&#x72;&#66;&#x75;&#x2e;&#x78;&#120;&#x40;&#103;&#109;&#x61;&#105;&#108;&#x2e;&#x63;&#x6f;&#x6d;</a></p><p>ADD dist /usr/share/nginx/html<br><code>`</code></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;本文使用操作系统为 CentOS 7，Jenkins 版本为 2.277.1&lt;/p&gt;
&lt;h1 id=&quot;零、准备工作&quot;&gt;&lt;a href=&quot;#零、准备工作&quot; class=&quot;headerlink&quot; title=&quot;零、准备工作&quot;&gt;&lt;/a&gt;零、准备工作&lt;/h1&gt;&lt;h2 id=&quot;0-1
      
    
    </summary>
    
      <category term="IT" scheme="http://victor.karonda.com/categories/IT/"/>
    
    
      <category term="JDK" scheme="http://victor.karonda.com/tags/JDK/"/>
    
      <category term="Alibaba" scheme="http://victor.karonda.com/tags/Alibaba/"/>
    
      <category term="Docker" scheme="http://victor.karonda.com/tags/Docker/"/>
    
      <category term="Kubernetes" scheme="http://victor.karonda.com/tags/Kubernetes/"/>
    
      <category term="Alibaba Cloud" scheme="http://victor.karonda.com/tags/Alibaba-Cloud/"/>
    
      <category term="Jenkins" scheme="http://victor.karonda.com/tags/Jenkins/"/>
    
      <category term="Maven" scheme="http://victor.karonda.com/tags/Maven/"/>
    
      <category term="Git" scheme="http://victor.karonda.com/tags/Git/"/>
    
      <category term="Node.js" scheme="http://victor.karonda.com/tags/Node-js/"/>
    
  </entry>
  
  <entry>
    <title>阿里云 k8s 部署 Spring Cloud Alibaba 微服务实践 (三) 服务观测</title>
    <link href="http://victor.karonda.com/2021/03/2121-alibaba-cloud-k8s-spring-cloud-alibaba-3/"/>
    <id>http://victor.karonda.com/2021/03/2121-alibaba-cloud-k8s-spring-cloud-alibaba-3/</id>
    <published>2021-03-22T07:00:00.000Z</published>
    <updated>2021-05-18T01:00:00.000Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>可观测性指如何从外部输出推断及衡量系统内部状态。Kubernetes 可观测性体系包含监控和日志两部分，监控可以帮助开发者查看系统的运行状态，而日志可以协助问题的排查和诊断从可观测性的角度，以 ACK（阿里云 Kubernetes） 为基础的系统架构可以粗略分为 4 个层次。自下而上分别是：基础设施层、容器性能层、应用性能层、用户业务层。</p></blockquote><p>直接使用阿里云提供的：阿里云托管版 Prometheus（ARMS Prometheus）、阿里云日志服务 SLS （Log Service），可以无需自行搭建 GPE、EFK 等。</p><h1 id="一、日志管理（采集程序日志）"><a href="#一、日志管理（采集程序日志）" class="headerlink" title="一、日志管理（采集程序日志）"></a>一、日志管理（采集程序日志）</h1><p>可直接参考：<a href="https://help.aliyun.com/document_detail/87540.html?spm=a2c4g.11186623.6.897.447e41aaWLKqUX" target="_blank" rel="noopener">通过日志服务采集Kubernetes容器日志</a></p><p>启用日志服务组件 Logtail 后，在第二步“容器配置”中的“日志配置”可以启用日志：</p><p><img src="https://victorblog.nos-eastchina1.126.net/2121/3/log-1.png" alt></p><p>根据提示操作即可，例如直接采集容器内日志可以在路径处填入：stdout，效果如下：</p><p><img src="https://victorblog.nos-eastchina1.126.net/2121/3/log-2.png" alt></p><h1 id="二、监控管理（采集程序性能指标）"><a href="#二、监控管理（采集程序性能指标）" class="headerlink" title="二、监控管理（采集程序性能指标）"></a>二、监控管理（采集程序性能指标）</h1><p>可直接参考：<a href="https://help.aliyun.com/document_detail/161304.html?spm=a2c4g.11186623.6.907.6a43388fp6ZAjR" target="_blank" rel="noopener">阿里云Prometheus监控</a></p><p>开启阿里云 Prometheus 监控后，在第三步“高级配置”中的“标签和注解”中添加 POD 注解：</p><p><img src="https://victorblog.nos-eastchina1.126.net/2121/3/prometheus.png" alt></p><p><strong>注意：是在 POD 添加注解，而不是在 Deployment 添加注解，官方文档没有特别说明，在此浪费了不少时间</strong></p><p>在“运维管理”中的“Prometheus 监控”点击右上角的“在新页面打开”即可打开 Grafana 页面：在 “+” 点击 “Import”，在 “Import via grafana.com” 下面的输入框，输入 4701，然后点击”Load”按钮：</p><p><img src="https://victorblog.nos-eastchina1.126.net/2121/3/grafana.png" alt></p><p><em>以下内容 2021/05/18 更新</em></p><p>阿里云日志服务默认不支持中文搜索，需要手动开启：</p><p>“日志服务”-“选中对应的 Project”-“选中对应的 logstore”-右上角“查询分析属性”-“属性”-开启“包含中文”</p><blockquote><p>参考</p></blockquote><ol><li><a href="https://help.aliyun.com/document_detail/203344.html?spm=a2c4g.11186623.6.897.447e41aaAP1rwH" target="_blank" rel="noopener">可观测性体系概述</a></li><li><a href="https://help.aliyun.com/document_detail/87540.html?spm=a2c4g.11186623.6.897.447e41aaWLKqUX" target="_blank" rel="noopener">通过日志服务采集Kubernetes容器日志</a></li><li><a href="https://help.aliyun.com/document_detail/161304.html?spm=a2c4g.11186623.6.907.6a43388fp6ZAjR" target="_blank" rel="noopener">阿里云Prometheus监控</a></li></ol>]]></content>
    
    <summary type="html">
    
      
      
        &lt;blockquote&gt;
&lt;p&gt;可观测性指如何从外部输出推断及衡量系统内部状态。Kubernetes 可观测性体系包含监控和日志两部分，监控可以帮助开发者查看系统的运行状态，而日志可以协助问题的排查和诊断从可观测性的角度，以 ACK（阿里云 Kubernetes） 为基础的系统架
      
    
    </summary>
    
      <category term="IT" scheme="http://victor.karonda.com/categories/IT/"/>
    
    
      <category term="Spring Cloud" scheme="http://victor.karonda.com/tags/Spring-Cloud/"/>
    
      <category term="Alibaba" scheme="http://victor.karonda.com/tags/Alibaba/"/>
    
      <category term="Grafana" scheme="http://victor.karonda.com/tags/Grafana/"/>
    
      <category term="Prometheus" scheme="http://victor.karonda.com/tags/Prometheus/"/>
    
      <category term="Kubernetes" scheme="http://victor.karonda.com/tags/Kubernetes/"/>
    
      <category term="Alibaba Cloud" scheme="http://victor.karonda.com/tags/Alibaba-Cloud/"/>
    
  </entry>
  
  <entry>
    <title>阿里云 k8s 部署 Spring Cloud Alibaba 微服务实践 (二) 部署微服务程序</title>
    <link href="http://victor.karonda.com/2021/03/2121-alibaba-cloud-k8s-spring-cloud-alibaba-2/"/>
    <id>http://victor.karonda.com/2021/03/2121-alibaba-cloud-k8s-spring-cloud-alibaba-2/</id>
    <published>2021-03-22T04:00:00.000Z</published>
    <updated>2021-03-22T04:00:00.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="零、镜像"><a href="#零、镜像" class="headerlink" title="零、镜像"></a>零、镜像</h1><h2 id="0-1-母镜像选择"><a href="#0-1-母镜像选择" class="headerlink" title="0.1. 母镜像选择"></a>0.1. 母镜像选择</h2><p>Alpine Linux 是一个面向安全应用的轻量级 Linux 发行版，基于 musl libc 和 busybox。Alpine 只有 5 M 左右，远远小于 CentOS 或 Ubuntu。</p><p>因为程序基于 Java 开发，所以微服务镜像需要 Java 1.8 的运行时环境支撑。项目选取 Oracle JDK 作为 Java 的运行时环境。最终使用的母镜像为：<a href="https://github.com/Docker-Hub-frolvlad/docker-alpine-oraclejre8" target="_blank" rel="noopener">frolvlad/alpine-oraclejre8:slim</a></p><h2 id="0-2-基础镜像"><a href="#0-2-基础镜像" class="headerlink" title="0.2. 基础镜像"></a>0.2. 基础镜像</h2><p>Alpine 默认时区是 UTC 时间，需要修改时区，即制作自己的基础镜像：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">FROM frolvlad/alpine-oraclejre8:slim</span><br><span class="line">MAINTAINER VictorBu &lt;VictorBu.xx@gmail.com&gt;</span><br><span class="line"></span><br><span class="line">RUN apk add tzdata \</span><br><span class="line">&amp;&amp; cp /usr/share/zoneinfo/Asia/Shanghai /etc/localtime \</span><br><span class="line">    &amp;&amp; echo &quot;Asia/Shanghai&quot; &gt; /etc/timezone \</span><br><span class="line">    &amp;&amp; apk del tzdata</span><br></pre></td></tr></table></figure><p>构建镜像并根据阿里云容器镜像服务将镜像上传，示例：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">docker build -t alpine-oraclejre8-base:1.0 .</span><br><span class="line"></span><br><span class="line">docker tag alpine-oraclejre8-base:1.0 registry.cn-shenzhen.aliyuncs.com/你的命名空间/alpine-oraclejre8-base:1.0</span><br><span class="line"></span><br><span class="line">docker push registry.cn-shenzhen.aliyuncs.com/你的命名空间/alpine-oraclejre8-base:1.0</span><br></pre></td></tr></table></figure><h2 id="0-3-业务镜像"><a href="#0-3-业务镜像" class="headerlink" title="0.3. 业务镜像"></a>0.3. 业务镜像</h2><p>示例（假设基础镜像的镜像名为：alpine-oraclejre8-base:1.0）</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">FROM alpine-oraclejre8-base:1.0</span><br><span class="line">MAINTAINER VictorBu &lt;VictorBu.xx@gmail.com&gt;</span><br><span class="line"></span><br><span class="line">ADD demo-0.0.1-SNAPSHOT.jar /demo.jar</span><br><span class="line">ENTRYPOINT [&quot;java&quot;, &quot;-jar&quot;, &quot;/demo.jar&quot;]</span><br></pre></td></tr></table></figure><p>构建镜像并根据阿里云容器镜像服务将镜像上传</p><h1 id="一、部署微服务程序"><a href="#一、部署微服务程序" class="headerlink" title="一、部署微服务程序"></a>一、部署微服务程序</h1><p>工作负载-&gt;无状态-&gt;点击右上角”使用镜像创建“，傻瓜式操作，根据界面提示一步步操作即可，然后再根据需要添加服务或者路由。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;零、镜像&quot;&gt;&lt;a href=&quot;#零、镜像&quot; class=&quot;headerlink&quot; title=&quot;零、镜像&quot;&gt;&lt;/a&gt;零、镜像&lt;/h1&gt;&lt;h2 id=&quot;0-1-母镜像选择&quot;&gt;&lt;a href=&quot;#0-1-母镜像选择&quot; class=&quot;headerlink&quot; title=
      
    
    </summary>
    
      <category term="IT" scheme="http://victor.karonda.com/categories/IT/"/>
    
    
      <category term="Spring Cloud" scheme="http://victor.karonda.com/tags/Spring-Cloud/"/>
    
      <category term="Alibaba" scheme="http://victor.karonda.com/tags/Alibaba/"/>
    
      <category term="Docker" scheme="http://victor.karonda.com/tags/Docker/"/>
    
      <category term="Kubernetes" scheme="http://victor.karonda.com/tags/Kubernetes/"/>
    
      <category term="Alibaba Cloud" scheme="http://victor.karonda.com/tags/Alibaba-Cloud/"/>
    
  </entry>
  
  <entry>
    <title>阿里云 k8s 部署 Spring Cloud Alibaba 微服务实践 (一) 部署 Nacos</title>
    <link href="http://victor.karonda.com/2021/03/2121-alibaba-cloud-k8s-spring-cloud-alibaba-1/"/>
    <id>http://victor.karonda.com/2021/03/2121-alibaba-cloud-k8s-spring-cloud-alibaba-1/</id>
    <published>2021-03-19T04:00:00.000Z</published>
    <updated>2021-03-19T04:00:00.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="零、准备工作"><a href="#零、准备工作" class="headerlink" title="零、准备工作"></a>零、准备工作</h1><h2 id="0-1-说明"><a href="#0-1-说明" class="headerlink" title="0.1. 说明"></a>0.1. 说明</h2><ol><li>目前官网提供的最新镜像的 Nacos 版本为 1.4.1，但是在部署过程中有问题，实际使用为 1.3.0</li><li>官方文档提供了自动伸缩的部署方式，但需要部署持久卷声明（PersistentVolumeClaim 简称 PVC），故目前仍采用固定数量的部署方式</li><li>官方文档使用的数据库是自己部署的，因为实际中使用阿里云，故直接使用阿里云 RDS （阿里云 k8s 部署的程序可以通过内网 IP 直接访问阿里云其他服务，如 RDS, Redis, Kafka 等）</li></ol><h2 id="0-2-连接-Kubernetes-集群配置"><a href="#0-2-连接-Kubernetes-集群配置" class="headerlink" title="0.2. 连接 Kubernetes 集群配置"></a>0.2. 连接 Kubernetes 集群配置</h2><p>如果需要在集群外的服务器执行 kubectl 命令，需要先进行连接 Kubernetes 集群配置：</p><p><img src="https://victorblog.nos-eastchina1.126.net/2121/1/kubectl.png" alt></p><h1 id="一、开始部署-Nacos"><a href="#一、开始部署-Nacos" class="headerlink" title="一、开始部署 Nacos"></a>一、开始部署 Nacos</h1><h2 id="1-1-初始化数据库"><a href="#1-1-初始化数据库" class="headerlink" title="1.1. 初始化数据库"></a>1.1. 初始化数据库</h2><p>下载 <a href="https://github.com/alibaba/nacos/releases/download/1.3.0/nacos-server-1.3.0.zip" target="_blank" rel="noopener">Nacos 1.3.0</a> ，然后在数据库执行 conf/nacos-mysql.sql 初始化数据库</p><h2 id="1-2-部署-Nacos"><a href="#1-2-部署-Nacos" class="headerlink" title="1.2. 部署 Nacos"></a>1.2. 部署 Nacos</h2><p>克隆 nacos-k8s 项目：<figure class="highlight plain"><figcaption><span>clone</span><a href="https://github.com/nacos-group/nacos-k8s.git```" target="_blank" rel="noopener">link</a></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">修改 ./deploy/nacos/nacos-quick-start.yaml 文件：</span><br></pre></td></tr></table></figure></p><hr><p>apiVersion: v1<br>kind: Service<br>metadata:<br>  name: nacos-headless<br>  labels:<br>    app: nacos-headless<br>spec:<br>  type: ClusterIP<br>  clusterIP: None<br>  ports:</p><pre><code>- port: 8848  name: server  targetPort: 8848- port: 7848  name: rpc  targetPort: 7848</code></pre><p>  selector:</p><pre><code>app: nacos</code></pre><hr><p>apiVersion: v1<br>kind: ConfigMap<br>metadata:<br>  name: nacos-cm<br>data:<br>  mysql.host: “阿里云 RDS 内网地址”<br>  mysql.db.name: “数据库名”<br>  mysql.port: “数据库端口”<br>  mysql.user: “数据库用户名”</p><h2 id="mysql-password-“数据库密码”"><a href="#mysql-password-“数据库密码”" class="headerlink" title="  mysql.password: “数据库密码”"></a>  mysql.password: “数据库密码”</h2><p>apiVersion: apps/v1<br>kind: StatefulSet<br>metadata:<br>  name: nacos<br>spec:<br>  serviceName: nacos-headless<br>  replicas: 3 # 实例数量<br>  template:<br>    metadata:<br>      labels:<br>        app: nacos<br>      annotations:<br>        pod.alpha.kubernetes.io/initialized: “true”<br>    spec:<br>      affinity:<br>        podAntiAffinity:<br>          requiredDuringSchedulingIgnoredDuringExecution:</p><pre><code>      - labelSelector:          matchExpressions:            - key: &quot;app&quot;              operator: In              values:                - nacos        topologyKey: &quot;kubernetes.io/hostname&quot;containers:  - name: k8snacos    imagePullPolicy: Always    image: nacos/nacos-server:1.3.0 # nacos 版本    resources:      requests:        memory: &quot;2Gi&quot;        cpu: &quot;500m&quot;    ports:      - containerPort: 8848        name: client      - containerPort: 7848        name: rpc    env:      - name: NACOS_REPLICAS        value: &quot;3&quot; # 实例数量      - name: MYSQL_SERVICE_HOST        valueFrom:          configMapKeyRef:            name: nacos-cm            key: mysql.host                     - name: MYSQL_SERVICE_DB_NAME        valueFrom:          configMapKeyRef:            name: nacos-cm            key: mysql.db.name      - name: MYSQL_SERVICE_PORT        valueFrom:          configMapKeyRef:            name: nacos-cm            key: mysql.port      - name: MYSQL_SERVICE_USER        valueFrom:          configMapKeyRef:            name: nacos-cm            key: mysql.user      - name: MYSQL_SERVICE_PASSWORD        valueFrom:          configMapKeyRef:            name: nacos-cm            key: mysql.password      - name: NACOS_SERVER_PORT        value: &quot;8848&quot;      - name: NACOS_APPLICATION_PORT        value: &quot;8848&quot;      - name: PREFER_HOST_MODE        value: &quot;hostname&quot;      - name: NACOS_SERVERS        value: &quot;nacos-0.nacos-headless.default.svc.cluster.local:8848 nacos-1.nacos-headless.default.svc.cluster.local:8848 nacos-2.nacos-headless.default.svc.cluster.local:8848&quot; # 如果调整了数量或者命名空间这里也需要调整</code></pre><p>  selector:<br>    matchLabels:<br>      app: nacos<br><code>`</code></p><p>在 nacos-k8s 根目录执行：<code>kubectl create -f ./deploy/nacos/nacos-quick-start.yaml</code>，刷新页面可以看到部署结果：</p><p><img src="https://victorblog.nos-eastchina1.126.net/2121/1/nacos.png" alt></p><blockquote><p>参考：</p></blockquote><ol><li><a href="https://github.com/nacos-group/nacos-k8s" target="_blank" rel="noopener">nacos-k8s</a></li><li><a href="https://github.com/nacos-group/nacos-docker" target="_blank" rel="noopener">nacos-docker</a></li><li><a href="https://github.com/alibaba/nacos" target="_blank" rel="noopener">nacos</a></li></ol>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;零、准备工作&quot;&gt;&lt;a href=&quot;#零、准备工作&quot; class=&quot;headerlink&quot; title=&quot;零、准备工作&quot;&gt;&lt;/a&gt;零、准备工作&lt;/h1&gt;&lt;h2 id=&quot;0-1-说明&quot;&gt;&lt;a href=&quot;#0-1-说明&quot; class=&quot;headerlink&quot; titl
      
    
    </summary>
    
      <category term="IT" scheme="http://victor.karonda.com/categories/IT/"/>
    
    
      <category term="Spring Cloud" scheme="http://victor.karonda.com/tags/Spring-Cloud/"/>
    
      <category term="Alibaba" scheme="http://victor.karonda.com/tags/Alibaba/"/>
    
      <category term="Nacos" scheme="http://victor.karonda.com/tags/Nacos/"/>
    
      <category term="Kubernetes" scheme="http://victor.karonda.com/tags/Kubernetes/"/>
    
      <category term="Alibaba Cloud" scheme="http://victor.karonda.com/tags/Alibaba-Cloud/"/>
    
  </entry>
  
  <entry>
    <title>k8s (七) 从应用访问 pod 元数据以及其他资源</title>
    <link href="http://victor.karonda.com/2021/01/2120-k8s-7/"/>
    <id>http://victor.karonda.com/2021/01/2120-k8s-7/</id>
    <published>2021-01-25T04:00:00.000Z</published>
    <updated>2021-01-25T04:00:00.000Z</updated>
    
    <content type="html"><![CDATA[<p>Downward API 可以给在 pod 中运行的进程暴露 pod 的元数据。目前我们可以给容器传递以下数据：</p><ul><li>pod 的名称</li><li>pod 的 IP</li><li>pod 所在的命名空间</li><li>pod 运行节点的名称</li><li>pod 运行所归属的服务账户的名称</li><li>每个容器请求的 CPU 和内存的使用量</li><li>每个容器可以使用的 CPU 和内存的限制</li><li>pod 的标签</li><li>pod 的注解</li></ul><h1 id="一、通过环境变量暴露元数据"><a href="#一、通过环境变量暴露元数据" class="headerlink" title="一、通过环境变量暴露元数据"></a>一、通过环境变量暴露元数据</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br></pre></td><td class="code"><pre><span class="line"># downward-api-env.yaml</span><br><span class="line"></span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: Pod</span><br><span class="line">metadata:</span><br><span class="line">  name: downward</span><br><span class="line">spec:</span><br><span class="line">  containers:</span><br><span class="line">  - name: main</span><br><span class="line">    image: busybox</span><br><span class="line">    command: [&quot;sleep&quot;, &quot;9999999&quot;]</span><br><span class="line">    resources:</span><br><span class="line">      requests:</span><br><span class="line">        cpu: 15m</span><br><span class="line">        memory: 100Ki</span><br><span class="line">      limits:</span><br><span class="line">        cpu: 100m</span><br><span class="line">        memory: 4Mi</span><br><span class="line">    env:</span><br><span class="line">    - name: POD_NAME</span><br><span class="line">      valueFrom:</span><br><span class="line">        fieldRef:</span><br><span class="line">          fieldPath: metadata.name # 引用 pod manifest 中的元数据名称字段，而不是设定一个具体的值</span><br><span class="line">    - name: POD_NAMESPACE</span><br><span class="line">      valueFrom:</span><br><span class="line">        fieldRef:</span><br><span class="line">          fieldPath: metadata.namespace</span><br><span class="line">    - name: POD_IP</span><br><span class="line">      valueFrom:</span><br><span class="line">        fieldRef:</span><br><span class="line">          fieldPath: status.podIP</span><br><span class="line">    - name: NODE_NAME</span><br><span class="line">      valueFrom:</span><br><span class="line">        fieldRef:</span><br><span class="line">          fieldPath: spec.nodeName</span><br><span class="line">    - name: SERVICE_ACCOUNT</span><br><span class="line">      valueFrom:</span><br><span class="line">        fieldRef:</span><br><span class="line">          fieldPath: spec.serviceAccountName</span><br><span class="line">    - name: CONTAINER_CPU_REQUEST_MILLICORES</span><br><span class="line">      valueFrom:</span><br><span class="line">        resourceFieldRef:</span><br><span class="line">          resource: requests.cpu</span><br><span class="line">          divisor: 1m</span><br><span class="line">    - name: CONTAINER_MEMORY_LIMIT_KIBIBYTES</span><br><span class="line">      valueFrom:</span><br><span class="line">        resourceFieldRef:</span><br><span class="line">          resource: limits.memory</span><br><span class="line">          divisor: 1Ki</span><br></pre></td></tr></table></figure><p><code>kubectl create -f downward-api-env.yaml</code></p><h1 id="二、通过-downwardAPI-卷来传递元数据"><a href="#二、通过-downwardAPI-卷来传递元数据" class="headerlink" title="二、通过 downwardAPI 卷来传递元数据"></a>二、通过 downwardAPI 卷来传递元数据</h1><p>暂略。。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;Downward API 可以给在 pod 中运行的进程暴露 pod 的元数据。目前我们可以给容器传递以下数据：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;pod 的名称&lt;/li&gt;
&lt;li&gt;pod 的 IP&lt;/li&gt;
&lt;li&gt;pod 所在的命名空间&lt;/li&gt;
&lt;li&gt;pod 运行节点的名称
      
    
    </summary>
    
      <category term="IT" scheme="http://victor.karonda.com/categories/IT/"/>
    
    
      <category term="Kubernetes" scheme="http://victor.karonda.com/tags/Kubernetes/"/>
    
  </entry>
  
  <entry>
    <title>k8s (六) ConfigMap 和 Secret：配置应用程序</title>
    <link href="http://victor.karonda.com/2021/01/2120-k8s-6/"/>
    <id>http://victor.karonda.com/2021/01/2120-k8s-6/</id>
    <published>2021-01-21T04:00:00.000Z</published>
    <updated>2021-01-21T04:00:00.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="一、向容器传递命令行参数"><a href="#一、向容器传递命令行参数" class="headerlink" title="一、向容器传递命令行参数"></a>一、向容器传递命令行参数</h1><h2 id="1-1-在-Docker-中定义命令与参数"><a href="#1-1-在-Docker-中定义命令与参数" class="headerlink" title="1.1. 在 Docker 中定义命令与参数"></a>1.1. 在 Docker 中定义命令与参数</h2><p>容器中运行的完整指令由两部分组成：命令与参数。</p><p>ENTRYPOINT 与 CMD：</p><ul><li>ENTRYPOINT：定义容器启动时被调用的可执行程序。</li><li>CMD：指定传递给 ENTRYPOINT 的参数。</li></ul><p>尽管可以直接使用 CMD 指令指定镜像运行时想要执行的命令，正确的做法依旧是借助 ENTRYPOINT 指令，仅仅用 CMD 指定所需的默认参数。这样，镜像可以直接运行，无须添加任何参数：</p><figure class="highlight docker"><figcaption><span>run <image>```</image></span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">或者是添加一些参数，覆盖 Dockerfile 中任何由 <span class="keyword">CMD</span> 指定的默认参数值：</span><br><span class="line"></span><br><span class="line">```docker <span class="keyword">run</span> &lt;image&gt; &lt;arguments&gt;</span><br></pre></td></tr></table></figure><p>shell 与 exec 形式的区别：</p><ul><li>shell 形式：如 ENTRYPOINT node app.js</li><li>exec 形式：如 ENTRYPOINT [“node”, “app.js”]</li></ul><p>两者的区别在于指定的命令是否是在 shell 中被调用。exec 形式的 ENTRYPOINT 指令是直接运行 node 进程；shell 形式的指令主进程（PID 1）是 shell 进程而非 node 进程，node 进程于 shell 中启动。shell 进程往往是多余的，因此通常可以直接采用 exec 形式的 ENTRYPOINT 指令。</p><p>实例：</p><p>luksa/fortune:args 镜像中的运行脚本：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">#!/bin/bash</span><br><span class="line">trap &quot;exit&quot; SIGINT</span><br><span class="line"></span><br><span class="line">INTERVAL=$1</span><br><span class="line">echo Configured to generate new fortune every $INTERVAL seconds</span><br><span class="line"></span><br><span class="line">mkdir -p /var/htdocs</span><br><span class="line"></span><br><span class="line">while :</span><br><span class="line">do</span><br><span class="line">  echo $(date) Writing fortune to /var/htdocs/index.html</span><br><span class="line">  /usr/games/fortune &gt; /var/htdocs/index.html</span><br><span class="line">  sleep $INTERVAL</span><br><span class="line">done</span><br></pre></td></tr></table></figure><p>luksa/fortune:args 的 Dockerfile 内容：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">FROM ubuntu:latest</span><br><span class="line"></span><br><span class="line">RUN apt-get update ; apt-get -y install fortune</span><br><span class="line">ADD fortuneloop.sh /bin/fortuneloop.sh</span><br><span class="line"></span><br><span class="line">ENTRYPOINT [&quot;/bin/fortuneloop.sh&quot;]</span><br><span class="line">CMD [&quot;10&quot;]</span><br></pre></td></tr></table></figure><p>测试：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">docker run -it luksa/fortune:args # 默认的 10 秒钟</span><br><span class="line">docker run -it luksa/fortune:args 15 # 传参修改为 15 秒钟</span><br></pre></td></tr></table></figure><h2 id="1-2-在-Kubernetes-中覆盖命令和参数"><a href="#1-2-在-Kubernetes-中覆盖命令和参数" class="headerlink" title="1.2. 在 Kubernetes 中覆盖命令和参数"></a>1.2. 在 Kubernetes 中覆盖命令和参数</h2><p>在 Kubernetes 中定义容器时，镜像的 ENTRYPOINT 和  CMD 均可以被覆盖，仅需要在容器定义中设置 command 和 args 的值：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">kind: Pod</span><br><span class="line">spec:</span><br><span class="line">  containers:</span><br><span class="line">  - image: some/image</span><br><span class="line">    command: [&quot;/bin/command&quot;] # 对应 ENTRYPOINT</span><br><span class="line">    args: [&quot;arg1&quot;, &quot;arg2&quot;, &quot;arg3&quot;] # 对应 CMD，多参数值可以使用 &quot;-&quot; 数组的形式（字符串值无须用引号标记，数值需要）</span><br></pre></td></tr></table></figure><p>注意：command 和 args 字段在 pod 创建后无法被修改。绝大多数情况下，只需要设置自定义参数。命令一般很少被覆盖，除非针对一些未定义 ENTRYPOINT 的通用镜像。</p><h1 id="二、为容器设置环境变量"><a href="#二、为容器设置环境变量" class="headerlink" title="二、为容器设置环境变量"></a>二、为容器设置环境变量</h1><p>在容器定义中指定环境变量：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: v1</span><br><span class="line">kind: Pod</span><br><span class="line">metadata:</span><br><span class="line">  name: fortune-env</span><br><span class="line">spec:</span><br><span class="line">  containers:</span><br><span class="line">  - image: luksa/fortune:env</span><br><span class="line">    env:</span><br><span class="line">    - name: INTERVAL</span><br><span class="line">      value: &quot;30&quot;</span><br></pre></td></tr></table></figure><p>在环境变量值中引用其他环境变量：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">env:</span><br><span class="line">- name: FIRST_VAR</span><br><span class="line">  value: &quot;foo&quot;</span><br><span class="line">- name: SECOND_VAR</span><br><span class="line">  value: &quot;$(FIRST_VAR)bar&quot;</span><br></pre></td></tr></table></figure><h1 id="三、利用-ConfigMap-解耦配置"><a href="#三、利用-ConfigMap-解耦配置" class="headerlink" title="三、利用 ConfigMap 解耦配置"></a>三、利用 ConfigMap 解耦配置</h1><p>Kubernetes 允许将配置选项分离到单独的资源对象 ConfigMap 中，本质上就是一个键/值对映射，值可以是短字面量，也可以是完整的配置文件。应用无须直接读取 ConfigMap，甚至根本不需要知道其是否存在。映射的内容通过环境变量或者卷文件的形式传递给容器，而并非直接传递给容器。</p><h2 id="3-1-创建-ConfigMap"><a href="#3-1-创建-ConfigMap" class="headerlink" title="3.1. 创建 ConfigMap"></a>3.1. 创建 ConfigMap</h2><h3 id="3-1-1-使用指令创建-ConfigMap"><a href="#3-1-1-使用指令创建-ConfigMap" class="headerlink" title="3.1.1. 使用指令创建 ConfigMap"></a>3.1.1. 使用指令创建 ConfigMap</h3><figure class="highlight plain"><figcaption><span>create configmap fortune-config --from-literal</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">创建了一个叫 fortune-config 的 ConfigMap，只包含一个条目。也可以添加多个条目：</span><br><span class="line"></span><br><span class="line">```kubectl create configmap myconfigmap --from-literal=foo=bar --from-literal=bar=baz --from-literal=one=two</span><br></pre></td></tr></table></figure><p>注意：ConfigMap 中的键名必须是一个合法的 DNS 子域，仅包含数字字母、破折号、下划线以及圆点。</p><p>查看创建的 ConfigMap 的 YAML 格式的定义描述：</p><figure class="highlight plain"><figcaption><span>get configmap fortune-config -o yaml```</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"></span><br><span class="line">### 3.1.2. 从文件内容创建 ConfigMap 目录</span><br><span class="line"></span><br><span class="line">```kubectl create configmap my-config --from-file=config-file.conf</span><br></pre></td></tr></table></figure><p>默认使用文件名作为键名，也可以手动指定键名：</p><figure class="highlight plain"><figcaption><span>create configmap my-config --from-file</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">多次使用 --from-file 参数可增加多个文件条目。</span><br><span class="line"></span><br><span class="line">### 3.1.3. 从文件夹创建 ConfigMap</span><br><span class="line"></span><br><span class="line">```kubectl create configmap my -config --from-file=/path/to/dir</span><br></pre></td></tr></table></figure><p>为文件夹中的每个文件单独创建条目，仅限于那些文件名可作为合法 ConfigMap 键名的文件</p><h3 id="3-1-4-合并不同选项"><a href="#3-1-4-合并不同选项" class="headerlink" title="3.1.4. 合并不同选项"></a>3.1.4. 合并不同选项</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">kubectl create configmap my -config</span><br><span class="line">  --from-file=foo.json # 单独的文件</span><br><span class="line">  --from-file=bar=foobar.conf # 自定义键名条目下的文件</span><br><span class="line">  --from-file=config-opts/ # 完整的文件夹</span><br><span class="line">  --from-file=some=thing # 字面量</span><br></pre></td></tr></table></figure><h2 id="3-2-给容器传递-ConfigMap-条目作为环境变量"><a href="#3-2-给容器传递-ConfigMap-条目作为环境变量" class="headerlink" title="3.2. 给容器传递 ConfigMap 条目作为环境变量"></a>3.2. 给容器传递 ConfigMap 条目作为环境变量</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: v1</span><br><span class="line">kind: Pod</span><br><span class="line">metadata:</span><br><span class="line">  name: fortune-env-from-configmap</span><br><span class="line">spec:</span><br><span class="line">  containers:</span><br><span class="line">  - image: luksa/fortune:env</span><br><span class="line">    env:</span><br><span class="line">    - name: INTERVAL # 环境变量名为 INTERVAL</span><br><span class="line">      valueFrom: </span><br><span class="line">        configMapKeyRef: # ConfigMap</span><br><span class="line">          name: fortune-config # ConfigMap 名称</span><br><span class="line">          key: sleep-interval # ConfigMap 对应键的值</span><br><span class="line">... ...</span><br></pre></td></tr></table></figure><p>在 pod 中引用不存在的 ConfigMap，如果没有设置 configMapKeyRef.optional: true 则容器会启动失败，如果之后创建了这个缺失的 ConfigMap，失败容器会自动启动，无须重新创建 pod</p><h2 id="3-3-一次性传递-ConfigMap-的所有条目作为环境变量"><a href="#3-3-一次性传递-ConfigMap-的所有条目作为环境变量" class="headerlink" title="3.3. 一次性传递 ConfigMap 的所有条目作为环境变量"></a>3.3. 一次性传递 ConfigMap 的所有条目作为环境变量</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">spec:</span><br><span class="line">  containers:</span><br><span class="line">  - image: some-image</span><br><span class="line">    envFrom:</span><br><span class="line">    - prefix: CONFIG_ # 所有环境变量的前缀，可以不设置</span><br><span class="line">      configMapRef: </span><br><span class="line">        name: my-config-map</span><br><span class="line">... ...</span><br></pre></td></tr></table></figure><h2 id="3-4-传递-ConfigMap-条目作为命令行参数"><a href="#3-4-传递-ConfigMap-条目作为命令行参数" class="headerlink" title="3.4. 传递 ConfigMap 条目作为命令行参数"></a>3.4. 传递 ConfigMap 条目作为命令行参数</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: v1</span><br><span class="line">kind: Pod</span><br><span class="line">metadata:</span><br><span class="line">  name: fortune-args-from-configmap</span><br><span class="line">spec:</span><br><span class="line">  containers:</span><br><span class="line">  - image: luksa/fortune:args</span><br><span class="line">    env:</span><br><span class="line">    - name: INTERVAL</span><br><span class="line">      valueFrom: </span><br><span class="line">        configMapKeyRef:</span><br><span class="line">          name: fortune-config</span><br><span class="line">          key: sleep-interval</span><br><span class="line">    args: [&quot;$(INTERVAL)&quot;] # 在参数设置中引用环境变量</span><br><span class="line">... ...</span><br></pre></td></tr></table></figure><h2 id="3-5-使用-ConfigMap-卷将条目暴露为文件"><a href="#3-5-使用-ConfigMap-卷将条目暴露为文件" class="headerlink" title="3.5. 使用 ConfigMap 卷将条目暴露为文件"></a>3.5. 使用 ConfigMap 卷将条目暴露为文件</h2><h3 id="3-5-1-创建-ConfigMap"><a href="#3-5-1-创建-ConfigMap" class="headerlink" title="3.5.1. 创建 ConfigMap"></a>3.5.1. 创建 ConfigMap</h3><p>新建文件夹 configmap-files 并将 my-nginx-config.conf 和 sleep-interval 放置在文件夹下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"># my-nginx-config.conf</span><br><span class="line"></span><br><span class="line">server &#123;</span><br><span class="line">    listen              80;</span><br><span class="line">    server_name         www.kubia-example.com;</span><br><span class="line"></span><br><span class="line">    gzip on;</span><br><span class="line">    gzip_types text/plain application/xml;</span><br><span class="line"></span><br><span class="line">    location / &#123;</span><br><span class="line">        root   /usr/share/nginx/html;</span><br><span class="line">        index  index.html index.htm;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"># sleep-interval</span><br><span class="line"></span><br><span class="line">25</span><br></pre></td></tr></table></figure><p>先删除之前创建的 ConfigMap：</p><figure class="highlight plain"><figcaption><span>delete configmap fortune-config```</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">新建 ConfigMap：</span><br><span class="line"></span><br><span class="line">```kubectl create configmap fortune-config --from-file=configmap-files</span><br></pre></td></tr></table></figure><p>查看：</p><figure class="highlight plain"><figcaption><span>get configmap fortune-config -o yaml```</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">### 3.5.2. 在卷内使用 ConfigMap 的条目</span><br></pre></td></tr></table></figure><h1 id="fortune-pod-configmap-volume-yaml"><a href="#fortune-pod-configmap-volume-yaml" class="headerlink" title="fortune-pod-configmap-volume.yaml"></a>fortune-pod-configmap-volume.yaml</h1><h1 id="详见：https-github-com-luksa-kubernetes-in-action-blob-master-Chapter07-fortune-pod-configmap-volume-yaml"><a href="#详见：https-github-com-luksa-kubernetes-in-action-blob-master-Chapter07-fortune-pod-configmap-volume-yaml" class="headerlink" title="详见：https://github.com/luksa/kubernetes-in-action/blob/master/Chapter07/fortune-pod-configmap-volume.yaml"></a>详见：<a href="https://github.com/luksa/kubernetes-in-action/blob/master/Chapter07/fortune-pod-configmap-volume.yaml" target="_blank" rel="noopener">https://github.com/luksa/kubernetes-in-action/blob/master/Chapter07/fortune-pod-configmap-volume.yaml</a></h1><p>apiVersion: v1<br>kind: Pod<br>metadata:<br>  name: fortune-configmap-volume<br>spec:<br>  containers:<br>  … …</p><ul><li>image: nginx:alpine<br>name: web-server<br>volumeMounts:<br>… …<ul><li>name: config<br>mountPath: /etc/nginx/conf.d # 挂载 configMap 卷至这个位置<br>readOnly: true<br>… …<br>volumes:<br>… …</li></ul></li><li>name: config<br>configMap:<br>  name: fortune-config # 卷引用 fortune-config<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">创建：</span><br><span class="line"></span><br><span class="line">```kubectl create -f fortune-pod-configmap-volume.yaml</span><br></pre></td></tr></table></figure></li></ul><p>验证：</p><figure class="highlight plain"><figcaption><span>port-forward fortune-configmap-volume 8080:80 &```</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">```curl -H &quot;Accept-Encoding: gzip&quot; -I localhost:8080</span><br></pre></td></tr></table></figure><p>输出：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">... ...</span><br><span class="line">Content-Encoding: gzip</span><br></pre></td></tr></table></figure><p>注意：挂载某一文件夹会隐藏该文件夹中已存在的文件</p><h3 id="3-5-3-卷内暴露指定的-ConfigMap-条目"><a href="#3-5-3-卷内暴露指定的-ConfigMap-条目" class="headerlink" title="3.5.3. 卷内暴露指定的 ConfigMap 条目"></a>3.5.3. 卷内暴露指定的 ConfigMap 条目</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">  volumes:</span><br><span class="line">  - name: config</span><br><span class="line">    configMap:</span><br><span class="line">      name: fortune-config</span><br><span class="line">      items: # 选择包含在卷中的条目</span><br><span class="line">      - key: my-nginx-config.conf # 该键对应的条目被包含</span><br><span class="line">        path: gzip.conf # 条目的值被存储在该文件中</span><br><span class="line">`</span><br></pre></td></tr></table></figure><h3 id="3-5-4-ConfigMap-独立条目作为文件被挂载且不隐藏文件夹中的其他文件"><a href="#3-5-4-ConfigMap-独立条目作为文件被挂载且不隐藏文件夹中的其他文件" class="headerlink" title="3.5.4. ConfigMap 独立条目作为文件被挂载且不隐藏文件夹中的其他文件"></a>3.5.4. ConfigMap 独立条目作为文件被挂载且不隐藏文件夹中的其他文件</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">spec:</span><br><span class="line">  containers:</span><br><span class="line">  - image: some/image</span><br><span class="line">    volumeMounts:</span><br><span class="line">    - name: myvolume</span><br><span class="line">      mountPath: /etc/someconfig.conf # 挂载至某一文件而不是文件夹</span><br><span class="line">  subPath: myconfig.conf #仅挂载指定的条目 myconfig.conf 并非完整的卷</span><br></pre></td></tr></table></figure><h3 id="3-5-5-为-configMap-卷中的文件设置权限"><a href="#3-5-5-为-configMap-卷中的文件设置权限" class="headerlink" title="3.5.5. 为 configMap 卷中的文件设置权限"></a>3.5.5. 为 configMap 卷中的文件设置权限</h3><p>configMap 卷中所有文件的权限默认被设置为644 (-rw-r-r–)。可以通过卷规格定义中的 defaultMode 属性改变默认权限：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">volumes:</span><br><span class="line">- name: html</span><br><span class="line">  emptyDir: &#123;&#125;</span><br><span class="line">- name: config</span><br><span class="line">  configMap:</span><br><span class="line">    name: fortune-config</span><br><span class="line">    defaultMode: 0660 # 设置所有文件的权限为 -rw-rw------</span><br></pre></td></tr></table></figure><h2 id="3-6-更新应用配置且不重启应用程序"><a href="#3-6-更新应用配置且不重启应用程序" class="headerlink" title="3.6. 更新应用配置且不重启应用程序"></a>3.6. 更新应用配置且不重启应用程序</h2><p>使用环境变量或者命令行参数作为配置源的弊端在于无法在进程运行时更新配置。将 ConfigMap 暴露为卷可以达到配置热更新的效果，无须重新创建 pod 或者重启容器。ConfigMap 被更新之后，卷中引用它的所有文件也会相应更新，进程发现文件被改变之后进行重载。Kubernetes 同样支待文件更新之后手动通知容器。</p><p>修改 ConfigMap：</p><figure class="highlight plain"><figcaption><span>edit configmap fortune-config```</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">将 gzip on 改为 gzip off，ConfigMap 被更新不久之后会自动更新卷中的对应文件，查看：</span><br><span class="line"></span><br><span class="line">```kubectl exec fortune-configmap-volume -c web-server -- cat /etc/nginx/conf.d/my-nginx-config.conf</span><br></pre></td></tr></table></figure><p>通知 Nginx 重载配置：</p><figure class="highlight plain"><figcaption><span>exec fortune-configmap-volume -c web-server -- nginx -s reload```</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"># 四、使用 Secret 给容器传递敏感数据</span><br><span class="line"></span><br><span class="line">Secret 的使用方法也与ConfigMap 相同，可以：</span><br><span class="line"></span><br><span class="line">+ 将 Secret 条目作为环境变量传递给容器</span><br><span class="line">+ 将 Secret 条目暴露为卷中的文件</span><br><span class="line"></span><br><span class="line">Secret 只会存储在节点的内存中，永不写入物理存储，这样从节点上删除 Secret 时就不需要擦除磁盘</span><br><span class="line"></span><br><span class="line">创建 Secret：</span><br><span class="line"></span><br><span class="line">```kubectl create secret generic fortune-https --from-file=https.key --from-file=https.cert --from-file=foo</span><br></pre></td></tr></table></figure><p>https.key, https.cert, foo 文件内容见 <a href="https://github.com/luksa/kubernetes-in-action/tree/master/Chapter07/fortune-https" target="_blank" rel="noopener">链接</a></p><p>查看：</p><figure class="highlight plain"><figcaption><span>get secret fortune-https -o yaml```</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">Secret 条目的内容会被以 Base64 格式编码，这种区别导致在处理 YAML 和 JSON 格式的 Secret 时会稍许有些麻烦，可以通过 stringData 字段设置条目的纯文本值。</span><br><span class="line"></span><br><span class="line">通过 secret 卷将 Secret 暴露给容器之后，Secret 条目的值会被解码并以真实形式（纯文本或二进制）写入对应的文件。通过环境变量暴露 Secret 条目亦是如此。在这两种情况下，应用程序均无须主动解码，可直接读取文件内容或者查找环境变量。</span><br><span class="line"></span><br><span class="line">修改 fortune-config ConfigMap 以开启 HTTPS：</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">```kubectl edit configmap fortune-config</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">... ...</span><br><span class="line"></span><br><span class="line">server &#123;</span><br><span class="line">    listen              80;</span><br><span class="line">    listen              443 ssl;</span><br><span class="line">    server_name         www.kubia-example.com;</span><br><span class="line">    ssl_certificate     certs/https.cert; # /etc/nginx 的相对位置</span><br><span class="line">    ssl_certificate_key certs/https.key; # /etc/nginx 的相对位置</span><br><span class="line">    ssl_protocols       TLSv1 TLSv1.1 TLSv1.2;</span><br><span class="line">    ssl_ciphers         HIGH:!aNULL:!MD5;</span><br><span class="line">... ...</span><br></pre></td></tr></table></figure><p>挂载 fortune-secret 至 pod：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line"># fortune-pod-https.yaml</span><br><span class="line"></span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: Pod</span><br><span class="line">metadata:</span><br><span class="line">  name: fortune-https</span><br><span class="line">spec:</span><br><span class="line">  containers:</span><br><span class="line">  - image: luksa/fortune:env</span><br><span class="line">    name: html-generator</span><br><span class="line">    env:</span><br><span class="line">    - name: INTERVAL</span><br><span class="line">      valueFrom: </span><br><span class="line">        configMapKeyRef:</span><br><span class="line">          name: fortune-config</span><br><span class="line">          key: sleep-interval</span><br><span class="line">    volumeMounts:</span><br><span class="line">    - name: html</span><br><span class="line">      mountPath: /var/htdocs</span><br><span class="line">  - image: nginx:alpine</span><br><span class="line">    name: web-server</span><br><span class="line">    volumeMounts:</span><br><span class="line">    - name: html</span><br><span class="line">      mountPath: /usr/share/nginx/html</span><br><span class="line">      readOnly: true</span><br><span class="line">    - name: config</span><br><span class="line">      mountPath: /etc/nginx/conf.d</span><br><span class="line">      readOnly: true</span><br><span class="line">    - name: certs</span><br><span class="line">      mountPath: /etc/nginx/certs/ # 配置 Nginx 从 /etc/nginx/certs 中读取证书和密钥文件</span><br><span class="line">      readOnly: true</span><br><span class="line">    ports:</span><br><span class="line">    - containerPort: 80</span><br><span class="line">    - containerPort: 443</span><br><span class="line">  volumes:</span><br><span class="line">  - name: html</span><br><span class="line">    emptyDir: &#123;&#125;</span><br><span class="line">  - name: config</span><br><span class="line">    configMap:</span><br><span class="line">      name: fortune-config</span><br><span class="line">      items:</span><br><span class="line">      - key: my-nginx-config.conf</span><br><span class="line">        path: https.conf</span><br><span class="line">  - name: certs</span><br><span class="line">    secret:</span><br><span class="line">      secretName: fortune-https # secret 卷</span><br></pre></td></tr></table></figure><figure class="highlight plain"><figcaption><span>create -f fortune-pod-https.yaml```</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">测试：</span><br><span class="line"></span><br><span class="line">```kubectl port-forward fortune-https 8443:443 &amp;</span><br></pre></td></tr></table></figure><p><code>curl https://localhost:8443 -k</code></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;一、向容器传递命令行参数&quot;&gt;&lt;a href=&quot;#一、向容器传递命令行参数&quot; class=&quot;headerlink&quot; title=&quot;一、向容器传递命令行参数&quot;&gt;&lt;/a&gt;一、向容器传递命令行参数&lt;/h1&gt;&lt;h2 id=&quot;1-1-在-Docker-中定义命令与参数&quot;&gt;&lt;a
      
    
    </summary>
    
      <category term="IT" scheme="http://victor.karonda.com/categories/IT/"/>
    
    
      <category term="Kubernetes" scheme="http://victor.karonda.com/tags/Kubernetes/"/>
    
  </entry>
  
  <entry>
    <title>k8s (五) 卷：将磁盘挂载到容器</title>
    <link href="http://victor.karonda.com/2021/01/2120-k8s-5/"/>
    <id>http://victor.karonda.com/2021/01/2120-k8s-5/</id>
    <published>2021-01-20T04:00:00.000Z</published>
    <updated>2021-01-20T04:00:00.000Z</updated>
    
    <content type="html"><![CDATA[<p>Kubernetes 的卷是 pod 的 一 个组成部分，并和 pod 共享相同的生命周期。</p><h1 id="一、通过卷在容器之间共享数据"><a href="#一、通过卷在容器之间共享数据" class="headerlink" title="一、通过卷在容器之间共享数据"></a>一、通过卷在容器之间共享数据</h1><h2 id="1-1-使用-emptyDir-卷"><a href="#1-1-使用-emptyDir-卷" class="headerlink" title="1.1. 使用 emptyDir 卷"></a>1.1. 使用 emptyDir 卷</h2><p>创建一个 pod 中有两个共用同一个卷的容器：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"># fortune-pod.yaml</span><br><span class="line"></span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: Pod</span><br><span class="line">metadata:</span><br><span class="line">  name: fortune</span><br><span class="line">spec:</span><br><span class="line">  containers:</span><br><span class="line">  - image: luksa/fortune</span><br><span class="line">    name: html-generator</span><br><span class="line">    volumeMounts: # 名为 html 的卷挂载在容器的 /var/htdocs 中</span><br><span class="line">    - name: html</span><br><span class="line">      mountPath: /var/htdocs</span><br><span class="line">  - image: nginx:alpine</span><br><span class="line">    name: web-server</span><br><span class="line">    volumeMounts: # 名为 html 的卷挂载在容器的 /usr/share/nginx/html 中，并且只读</span><br><span class="line">    - name: html</span><br><span class="line">      mountPath: /usr/share/nginx/html # Nginx 服务的默认服务文件目录</span><br><span class="line">      readOnly: true</span><br><span class="line">    ports:</span><br><span class="line">    - containerPort: 80</span><br><span class="line">      protocol: TCP</span><br><span class="line">  volumes:</span><br><span class="line">  - name: html # 一个名为 html 的单独 emptyDir 卷，挂载在上面的两个容器中</span><br><span class="line">    emptyDir: &#123;&#125;</span><br></pre></td></tr></table></figure><p>luksa/fortune 每隔 10 秒钟随机写入一段文字到 /var/htdocs/index.html 中；nginx:alpine 是一个 Nginx 镜像。</p><figure class="highlight plain"><figcaption><span>create -f fortune-pod.yaml```</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">使用端口转发查看 pod 状态：</span><br><span class="line"></span><br><span class="line">```kubectl port-forward fortune 8080:80</span><br></pre></td></tr></table></figure><p>作为卷来使用的 emptyDir 是在承载 pod 的工作节点的实际磁盘上创建的，因此其性能取决于节点的磁盘类型。我们可以通知 Kubernetes 在 tmfs 文件系统（存在内存而非硬盘）上创建 emptyDir：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">volumes:</span><br><span class="line">- name: html</span><br><span class="line">  emptyDir:</span><br><span class="line"> medium: Memory</span><br></pre></td></tr></table></figure><h2 id="1-2-使用-Git-仓库作为存储卷"><a href="#1-2-使用-Git-仓库作为存储卷" class="headerlink" title="1.2. 使用 Git 仓库作为存储卷"></a>1.2. 使用 Git 仓库作为存储卷</h2><p>gitRepo 卷本质上也是 emptyDir 卷，它通过克隆 Git 仓库并在 pod 启动时（但在创建容器之前）检出特定版本来填充数据。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: v1</span><br><span class="line">kind: Pod</span><br><span class="line">metadata:</span><br><span class="line">  name: gitrepo-volume-pod</span><br><span class="line">spec:</span><br><span class="line">  containers:</span><br><span class="line">  - image: nginx:alpine</span><br><span class="line">    name: web-server</span><br><span class="line">    volumeMounts:</span><br><span class="line">    - name: html</span><br><span class="line">      mountPath: /usr/share/nginx/html</span><br><span class="line">      readOnly: true</span><br><span class="line">    ports:</span><br><span class="line">    - containerPort: 80</span><br><span class="line">      protocol: TCP</span><br><span class="line">  volumes:</span><br><span class="line">  - name: html</span><br><span class="line">    gitRepo:</span><br><span class="line">      repository: https://github.com/luksa/kubia-website-example.git</span><br><span class="line">      revision: master</span><br><span class="line">      directory: . # 将 repo 克隆到卷的根目录，如果不设置将会被克隆到 kubia-website-example 目录</span><br></pre></td></tr></table></figure><h1 id="二、访问工作节点文件系统上的文件"><a href="#二、访问工作节点文件系统上的文件" class="headerlink" title="二、访问工作节点文件系统上的文件"></a>二、访问工作节点文件系统上的文件</h1><p>大多数 pod 应该忽略它们的主机节点，因此它们不应该访问节点文件系统上的任何文件。但是某些系统级别的 pod (切记，这些通常由 DaemonSet 管理）确实需要读取节点的文件或使用节点文件系统来访问节点设备。Kubernetes 通过 hostPath 卷实现了这一点。</p><p>hostPath 卷是我们介绍的第一种类型的持久性存储，因为gitRepo 和 emptyDir 卷的内容都会在 pod 被删除时被删除，而 hostPath 卷的内容则不会被删除。如果你正在考虑使用 hostPath 卷作为存储数据库数据的目录，请重新考虑。因为卷的内容存储在特定节点的文件系统中，所以当数据库 pod 被重新安排在另一个节点时，会找不到数据。这解释了为什么对常规 pod 使用 hostPath 卷不是一个好主意，因为这会使 pod 对预定规划的节点很敏感。</p><h1 id="三、使用持久化存储"><a href="#三、使用持久化存储" class="headerlink" title="三、使用持久化存储"></a>三、使用持久化存储</h1><p>当运行在一个 pod 中的应用程序需要将数据保存到磁盘上，并且即使该 pod 重新调度到另一个节点时也要求具有相同的数据可用。这就不能使用到目前为止我们提到的任何卷类型，由于这些数据需要可以从任何集群节点访问，因此必须将其存储在某种类型的网络存储 (NAS) 中。</p><p>如果使用 Google Kubernetes Engine 可以使用 GCE (Google Compute Engine) 卷；如果使用 AWS EC2 可以使用 awsElasticBlockStore 卷；如果使用 Azure 可以使用 azureFile 或者 azureDisk 卷。</p><h1 id="四、从底层存储技术解耦-pod"><a href="#四、从底层存储技术解耦-pod" class="headerlink" title="四、从底层存储技术解耦 pod"></a>四、从底层存储技术解耦 pod</h1><p>到目前为止，我们探索过的所有待久卷类型都要求 pod 的开发人员了解集群中可用的真实网络存储的基础结构。例如，要创建支持 NFS 协议的卷，开发人员必须知道 NFS 节点所在的实际服务器。这违背了 Kubernetes 的基本理念，这个理念旨在向应用程序及其开发人员隐藏真实的基础设施，使他们不必担心基础设施的具体状<br>态，并使应用程序可在大量云服务商和数据企业之间进行功能迁移。</p><h2 id="4-1-持久卷、持久卷声明"><a href="#4-1-持久卷、持久卷声明" class="headerlink" title="4.1. 持久卷、持久卷声明"></a>4.1. 持久卷、持久卷声明</h2><p>在 Kubernetes 集群中为了使应用能够正常请求存储资源，同时避免处理基础设施细节，引入了两个新的资源， 分别是持久卷（PersistentVolume 简称 PV）和持久卷声明（PersistentVolumeClaim 简称 PVC），这名字可能有点误导，因为正如在前面几节中看到的，甚至常规的 Kubernetes 卷也可以用来存储持久性数据。</p><p>当集群用户需要在其 pod 中使用持久化存储时，他们首先创建持久卷声明清单，指定所需要的最低容量要求和访问模式，然后用户将持久卷声明清单提交给 Kubernetes API 服务器，Kubernetes 将找到可匹配的持久卷并将其绑定到持久卷声明。</p><h3 id="4-1-1-创建持久卷"><a href="#4-1-1-创建持久卷" class="headerlink" title="4.1.1. 创建持久卷"></a>4.1.1. 创建持久卷</h3><p>本文使用的依然是 Minikube:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"># mongodb-pv-hostpath.yaml</span><br><span class="line"></span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: PersistentVolume</span><br><span class="line">metadata:</span><br><span class="line">  name: mongodb-pv</span><br><span class="line">spec:</span><br><span class="line">  capacity: </span><br><span class="line">    storage: 1Gi # 定义 PersistentVolume de 大小</span><br><span class="line">  accessModes: # 可以被单个客户端挂在为读写模式或者被多个客户端挂在为只读模式</span><br><span class="line">    - ReadWriteOnce</span><br><span class="line">    - ReadOnlyMany</span><br><span class="line">  persistentVolumeReclaimPolicy: Retain # 当声明被释放后，PersistentVolume 将会被保留（不清理和删除）</span><br><span class="line">  hostPath:</span><br><span class="line">    path: /tmp/mongodb</span><br></pre></td></tr></table></figure><figure class="highlight plain"><figcaption><span>create -f mongodb-pv-hostpath.yaml```</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">查看：</span><br><span class="line"></span><br><span class="line">```kubectl get pv</span><br></pre></td></tr></table></figure><p>注意：持久卷不属于任何命名空间，它跟节点一样是集群层面的资源。</p><h3 id="4-1-2-创建持久卷声明"><a href="#4-1-2-创建持久卷声明" class="headerlink" title="4.1.2. 创建持久卷声明"></a>4.1.2. 创建持久卷声明</h3><p>假设现在需要部署一个需要持久化存储的 pod，将要用到之前创建的持久卷，但是不能直接在 pod 内使用，需要先声明一个。声明一个持久卷和创建一个 pod 是相对独立的过程，因为即使 pod 被重新调度（重新调度意味着先前的 pod 被删除并且创建了一个新的 pod），我们也希望通过相同的持久卷声明来确保可用。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"># mongodb-pvc.yaml</span><br><span class="line"></span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: PersistentVolumeClaim</span><br><span class="line">metadata:</span><br><span class="line">  name: mongodb-pvc # 声明的名称，稍后将声明当作 pod 的卷使用时需要用到</span><br><span class="line">spec:</span><br><span class="line">  resources:</span><br><span class="line">    requests:</span><br><span class="line">      storage: 1Gi # 申请 1 GiB 的存储空间</span><br><span class="line">  accessModes:</span><br><span class="line">  - ReadWriteOnce # 允许单个客户端访问（同时支持读取和写入操作）</span><br><span class="line">  storageClassName: &quot;&quot; # 将空字符串指定为存储类名可确保 PVC 绑定到预先配置的 PV, 而不是动态配置新的 PV</span><br></pre></td></tr></table></figure><figure class="highlight plain"><figcaption><span>create -f mongodb-pvc.yaml```</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"></span><br><span class="line">查看：</span><br><span class="line"></span><br><span class="line">```kubectl get pvc</span><br></pre></td></tr></table></figure><p>可以看到 PVC 已经与持久卷的 mongodb-pv 绑定。</p><p>访问模式：</p><ul><li>RWO: ReadWriteOnce - 仅允许单个节点挂载读写</li><li>ROX: ReadOnlyMany - 允许多个节点挂载只读</li><li>RWX: ReadWriteMany - 允许多个节点挂载读写</li></ul><p>访问模式涉及可以同时使用卷的工作节点的数量而非 pod 的数量。</p><p>持久卷是集群范围的，因此不能在特定的命名空间中创建，但是持久卷声明又只能在特定的命名空间创建，所以持久卷和持久卷声明只能被同一命名空间内的 pod 创建使用。</p><h1 id="4-1-3-在-pod-中使用持久卷声明"><a href="#4-1-3-在-pod-中使用持久卷声明" class="headerlink" title="4.1.3. 在 pod 中使用持久卷声明"></a>4.1.3. 在 pod 中使用持久卷声明</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"># mongodb-pod-pvc.yaml</span><br><span class="line"></span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: Pod</span><br><span class="line">metadata:</span><br><span class="line">  name: mongodb </span><br><span class="line">spec:</span><br><span class="line">  containers:</span><br><span class="line">  - image: mongo</span><br><span class="line">    name: mongodb</span><br><span class="line">    volumeMounts:</span><br><span class="line">    - name: mongodb-data</span><br><span class="line">      mountPath: /data/db</span><br><span class="line">    ports:</span><br><span class="line">    - containerPort: 27017</span><br><span class="line">      protocol: TCP</span><br><span class="line">  volumes:</span><br><span class="line">  - name: mongodb-data</span><br><span class="line">    persistentVolumeClaim:</span><br><span class="line">      claimName: mongodb-pvc # 在 pod 卷中通过名称引用持久卷声明</span><br></pre></td></tr></table></figure><h1 id="五、持久卷的动态卷配置"><a href="#五、持久卷的动态卷配置" class="headerlink" title="五、持久卷的动态卷配置"></a>五、持久卷的动态卷配置</h1><h2 id="5-1-通过-StorageClass-资源定义可用存储类型"><a href="#5-1-通过-StorageClass-资源定义可用存储类型" class="headerlink" title="5.1. 通过 StorageClass 资源定义可用存储类型"></a>5.1. 通过 StorageClass 资源定义可用存储类型</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"># storageclass-fast-hostpath.yaml</span><br><span class="line"></span><br><span class="line">apiVersion: storage.k8s.io/v1</span><br><span class="line">kind: StorageClass</span><br><span class="line">metadata:</span><br><span class="line">  name: fast</span><br><span class="line">provisioner: k8s.io/minikube-hostpath # 用户配置持久卷的卷插件</span><br><span class="line">parameters:</span><br><span class="line">  type: pd-ssd</span><br></pre></td></tr></table></figure><figure class="highlight plain"><figcaption><span>create -f storageclass-fast-hostpath.yaml```</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"># 5.2. 请求持久卷声明中的存储类</span><br><span class="line"></span><br><span class="line">创建一个请求特定存储类的 PVC 定义</span><br></pre></td></tr></table></figure><h1 id="mongodb-pvc-dp-yaml"><a href="#mongodb-pvc-dp-yaml" class="headerlink" title="mongodb-pvc-dp.yaml"></a>mongodb-pvc-dp.yaml</h1><p>apiVersion: v1<br>kind: PersistentVolumeClaim<br>metadata:<br>  name: mongodb-pvc-fast<br>spec:<br>  storageClassName: fast # 请求自定义存储类<br>  resources:<br>    requests:<br>      storage: 100Mi<br>  accessModes:</p><pre><code>- ReadWriteOnce</code></pre><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">```kubectl create -f mongodb-pvc-dp.yaml</span><br></pre></td></tr></table></figure><p>查看：</p><figure class="highlight plain"><figcaption><span>get pvc mongodb-pvc-fast```</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">VOLUME 列显示了与此声明绑定的持久卷，执行命令，可以看到自动创建了一个新的 PV:</span><br><span class="line"></span><br><span class="line">```kubectl get pv</span><br></pre></td></tr></table></figure><h1 id="5-3-不指定存储类的动态配置"><a href="#5-3-不指定存储类的动态配置" class="headerlink" title="5.3. 不指定存储类的动态配置"></a>5.3. 不指定存储类的动态配置</h1><p>列出存储类：</p><figure class="highlight plain"><figcaption><span>get sc # sc 是 storageclass 的简写```</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">查看默认存储类：</span><br><span class="line"></span><br><span class="line">```kubectl get sc standard -o yaml</span><br></pre></td></tr></table></figure><p>创建一个没有指定存储类别的持久卷声明：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"># mongodb-pvc-dp-nostorageclass.yaml</span><br><span class="line"></span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: PersistentVolumeClaim</span><br><span class="line">metadata:</span><br><span class="line">  name: mongodb-pvc2 </span><br><span class="line">spec:</span><br><span class="line">  resources:</span><br><span class="line">    requests:</span><br><span class="line">      storage: 100Mi</span><br><span class="line">  accessModes:</span><br><span class="line">    - ReadWriteOnce</span><br></pre></td></tr></table></figure><figure class="highlight plain"><figcaption><span>create -f mongodb-pvc-dp-nostorageclass.yaml```</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">查看：</span><br><span class="line"></span><br><span class="line">```kubectl get pvc mongodb-pvc2</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;Kubernetes 的卷是 pod 的 一 个组成部分，并和 pod 共享相同的生命周期。&lt;/p&gt;
&lt;h1 id=&quot;一、通过卷在容器之间共享数据&quot;&gt;&lt;a href=&quot;#一、通过卷在容器之间共享数据&quot; class=&quot;headerlink&quot; title=&quot;一、通过卷在容器之间
      
    
    </summary>
    
      <category term="IT" scheme="http://victor.karonda.com/categories/IT/"/>
    
    
      <category term="Kubernetes" scheme="http://victor.karonda.com/tags/Kubernetes/"/>
    
  </entry>
  
  <entry>
    <title>k8s (四) 服务：让客户端发现 pod 并与之通信</title>
    <link href="http://victor.karonda.com/2021/01/2120-k8s-4/"/>
    <id>http://victor.karonda.com/2021/01/2120-k8s-4/</id>
    <published>2021-01-19T05:00:00.000Z</published>
    <updated>2021-01-19T05:00:00.000Z</updated>
    
    <content type="html"><![CDATA[<p>服务是一种为一组功能相同的 pod 提供单一不变的接入点的资源。当服务存在时，它的 IP 地址和端口不会改变。客户端通过 IP 地址和端口号建立连接，这些连接会被路由到提供该服务的任意一个 pod 上。通过这种方式，客户端不需要知道每个单独的提供服务的 pod 的地址，这样这些 pod就可以在集群中随时被创建或移除。</p><h1 id="一、创建服务"><a href="#一、创建服务" class="headerlink" title="一、创建服务"></a>一、创建服务</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"># kubia-svc.yaml</span><br><span class="line"></span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: Service</span><br><span class="line">metadata:</span><br><span class="line">  name: kubia</span><br><span class="line">spec:</span><br><span class="line">  ports:</span><br><span class="line">  - port: 80 # 该服务的可用端口</span><br><span class="line">    targetPort: 8080 # 服务将连接转发到的容器端口</span><br><span class="line">  selector:</span><br><span class="line">    app: kubia # 具有 app=kubia 标签的 pod 都属于该服务</span><br></pre></td></tr></table></figure><p>创建：</p><figure class="highlight plain"><figcaption><span>create -f kubia-svc.yaml```</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">查看：</span><br><span class="line"></span><br><span class="line">``` kubectl get svc # svc 是 service 的简写</span><br></pre></td></tr></table></figure><p>（上篇文章已经通过 ReplicaSet 启动了 3 个 app=kubia 标签的 pod）通过 curl 命令即可看到效果：</p><figure class="highlight plain"><figcaption><span>10.96.9.157 # 10.96.9.157 为分配给服务的 IP```</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">在运行中的容器中远程执行命令：</span><br><span class="line"></span><br><span class="line">```kubectl exec kubia-ntxd8 -- curl -s 10.96.9.157</span><br></pre></td></tr></table></figure><p>双横杠(–) 代表着 kubectl 命令项的结束。双横杠之后的内容指在 pod 内部需要执行的命令。</p><h1 id="1-1-配置服务上的会话亲和性"><a href="#1-1-配置服务上的会话亲和性" class="headerlink" title="1.1. 配置服务上的会话亲和性"></a>1.1. 配置服务上的会话亲和性</h1><p>如果多次执行同样的命令，每次调用执行应该在不同的 pod 上。因为服务代理通常将每个连接随机指向选中的后端 pod 中的一个，即使连接来自于同一个客户端。如果希望特定客户端产生的所有请求每次都指向同一个 pod, 可以<br>设置服务的 sessionAffinity 属性为 ClientIP。Kubernetes 仅仅支持两种形式的会话亲和性服务：None（随机） 和 ClientIP，不支持 cookie，因为 Kubernetes 服务处理的是 TCP 和 UDP 而不是 HTTP。</p><h1 id="1-2-同一服务暴露多个端口"><a href="#1-2-同一服务暴露多个端口" class="headerlink" title="1.2. 同一服务暴露多个端口"></a>1.2. 同一服务暴露多个端口</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: v1</span><br><span class="line">kind: Service</span><br><span class="line">metadata:</span><br><span class="line">  name: kubia</span><br><span class="line">spec:</span><br><span class="line">  ports:</span><br><span class="line">  - name: http # 必须给每个端口指定名字</span><br><span class="line">    port: 80</span><br><span class="line">    targetPort: 8080</span><br><span class="line">  - name: https # 必须给每个端口指定名字</span><br><span class="line">    port: 443</span><br><span class="line">    targetPort: 8443</span><br><span class="line">  selector:</span><br><span class="line">    app: kubia</span><br></pre></td></tr></table></figure><h1 id="1-3-使用命名的端口"><a href="#1-3-使用命名的端口" class="headerlink" title="1.3. 使用命名的端口"></a>1.3. 使用命名的端口</h1><p>好处是即使更换端口号也无需更改服务 spec</p><p>在 pod 的定义中指定 port 名称：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">kind: Pod</span><br><span class="line">spec:</span><br><span class="line">  containers:</span><br><span class="line">  - image: luksa/kubia</span><br><span class="line">    name: kubia</span><br><span class="line">    ports:</span><br><span class="line">    - name: http</span><br><span class="line">      containerPort: 8080</span><br><span class="line">    - name: https</span><br><span class="line">      containerPort: 8443</span><br></pre></td></tr></table></figure><p>在服务中引用端口：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">kind: Service</span><br><span class="line">metadata:</span><br><span class="line">  name: kubia</span><br><span class="line">spec:</span><br><span class="line">  ports:</span><br><span class="line">  - name: http</span><br><span class="line">    port: 80</span><br><span class="line">    targetPort: http # 映射到容器中被称为 http 的端口</span><br><span class="line">  - name: https</span><br><span class="line">    port: 443</span><br><span class="line">    targetPort: https # 映射到容器中被称为 https 的端口 </span><br><span class="line">  selector:</span><br><span class="line">    app: kubia</span><br></pre></td></tr></table></figure><h1 id="二、服务发现"><a href="#二、服务发现" class="headerlink" title="二、服务发现"></a>二、服务发现</h1><h2 id="2-1-通过环境变量发现服务"><a href="#2-1-通过环境变量发现服务" class="headerlink" title="2.1. 通过环境变量发现服务"></a>2.1. 通过环境变量发现服务</h2><p>在 pod 开始运行的时候，Kubernetes 会初始化一系列的环境变量指向现在存在的服务。如果创建的服务<strong>早于</strong>客户端 pod 的创建，pod 上的进程可以根据环境变量获得服务的 IP 地址和端口号。</p><p>因为现有的 pod 创建于服务之前，所以需要先删除掉所有的 pod 这样 ReplicaSet 会创建全新的 pod：</p><p>删除 pod：</p><figure class="highlight plain"><figcaption><span>delete pods --all```</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">查看环境变量：</span><br><span class="line"></span><br><span class="line">```kubectl exec kubia-jkj9s -- env</span><br></pre></td></tr></table></figure><p>结果：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin</span><br><span class="line">... ...</span><br><span class="line">KUBIA_SERVICE_HOST=10.96.9.157</span><br><span class="line">KUBIA_SERVICE_PORT=80</span><br><span class="line"></span><br><span class="line">... ...</span><br></pre></td></tr></table></figure><p>服务名称中的横杠被转换为下划线，并且当服务名称用作环境变量名称中的前缀时，所有的字母都是大写的。</p><h2 id="2-2-通过-DNS-发现服务"><a href="#2-2-通过-DNS-发现服务" class="headerlink" title="2.2. 通过 DNS 发现服务"></a>2.2. 通过 DNS 发现服务</h2><p>通过 FQDN （全限定域名）连接服务：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">kubia 是服务名称，default 代表所在的命名空间；svc.cluster.local 是在所有集群本地服务名称中使用的可配置集群域后缀。（Kubernetes 通过修改每个容器的 /etc/resolv.conf 文件实现）</span><br><span class="line"></span><br><span class="line">注意：客户端仍然必须要知道服务的端口号，如果不是标准端口（80 或 5432），客户端可以从环境变量中获取端口号。</span><br><span class="line"></span><br><span class="line">在 pod 容器中运行 shell：</span><br><span class="line"></span><br><span class="line">```kubectl exec -it kubia-jkj9s bash</span><br></pre></td></tr></table></figure><p>访问服务：</p><figure class="highlight plain"><figcaption><span>http://kubia.default.svc.cluster.local```</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"># 三、连接集群外部的服务</span><br><span class="line"></span><br><span class="line">## 3.1. 服务的 endpoint</span><br><span class="line"></span><br><span class="line">服务和 pod 并不是直接相连的，而是通过 endpoint 资源。</span><br><span class="line"></span><br><span class="line">查看服务描述，可以看到包含 endpoint 的信息：</span><br><span class="line"></span><br><span class="line">```kubectl describe svc kubia</span><br></pre></td></tr></table></figure><p>endpoint 资源就是暴露一个服务的 IP 地址和端口的列表，也可以使用命令查看：</p><figure class="highlight plain"><figcaption><span>get endpoints kubia```</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">尽管在 spec 服务中定义了 pod 选择器，但在重定向传入连接时不会直接使用它。相反，选择器用于构建 IP 和端口列表，然后存储在 endpoint 资源中。当客户端连接到服务时，服务代理选择这些 IP 和端口对中的一个，并将传入连接重定向到在该位置监听的服务器。</span><br><span class="line"></span><br><span class="line">## 3.2. 手动配置服务的 endpoint</span><br><span class="line"></span><br><span class="line">如果创建了不包含 pod 选择器的服务， Kubernetes 将不会创建 endpoint 资源（毕</span><br><span class="line">竟缺少选择器，将不会知道服务中包含哪些 pod)。这样就需要创建 endpoint 资源来指定该服务的 endpoint 列表。</span><br><span class="line"></span><br><span class="line">## 3.2.1. 创建没有选择器的服务</span><br></pre></td></tr></table></figure><h1 id="external-service-yaml"><a href="#external-service-yaml" class="headerlink" title="external-service.yaml"></a>external-service.yaml</h1><p>apiVersion: v1<br>kind: Service<br>metadata:<br>  name: external-service # 服务的名字必须和 endpoint 对象的名字相匹配<br>spec:<br>  ports:</p><ul><li>port: 80<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">```kubectl create -f external-service.yaml</span><br></pre></td></tr></table></figure></li></ul><h2 id="3-2-2-创建-endpoint"><a href="#3-2-2-创建-endpoint" class="headerlink" title="3.2.2. 创建 endpoint"></a>3.2.2. 创建 endpoint</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"># external-service-endpoints.yaml</span><br><span class="line"></span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: Endpoints</span><br><span class="line">metadata:</span><br><span class="line">  name: external-service # endpoint 的名字必须和服务的名字相匹配</span><br><span class="line">subsets:</span><br><span class="line">  - addresses: # 服务将连接重定向到 endpoint 的 IP 地址</span><br><span class="line">    - ip: 11.11.11.11</span><br><span class="line">    - ip: 22.22.22.22</span><br><span class="line">    ports:</span><br><span class="line">    - port: 80 # endpoint 的目标端口</span><br></pre></td></tr></table></figure><figure class="highlight plain"><figcaption><span>create -f external-service-endpoints.yaml```</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">## 3.2.3. 为外部服务创建别名</span><br><span class="line"></span><br><span class="line">除了手动配置服务的 endpoint 来代替公开外部服务方法，有一种更简单的方法，就是通过其完全限定域名(FQDN)访问外部服务</span><br></pre></td></tr></table></figure><p>apiVersion: v1<br>kind: Service<br>metadata:<br>  name: external-service<br>spec:<br>  type: ExternalName # type 设置成 ExternalName<br>  externalName: api.somecompany.com # 实际服务的完全限定域名<br>  ports:</p><ul><li>port: 80<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">服务创建完成后 pod 可以通过 external-service.svc.cluster.local 域名连接到外部服务，而不是使用服务的实际 FQDN。</span><br><span class="line"></span><br><span class="line"># 四、将服务暴露给外部客户端</span><br><span class="line"></span><br><span class="line">有几种方式可以在外部访问服务：</span><br><span class="line"></span><br><span class="line">+ 将服务的类型设置成 NodePort：每个集群节点都会在节点上打开一个端口，对于 NodePort 服务，每个集群节点在节点本身（因此得名叫 NodePort)上打开一个端口，并将在该端口上接收到的流量重定向到基础服务。该服务仅在内部集群 IP 和端口上才可访间，但也可通过所有节点上的专用端口访问。</span><br><span class="line">+ 将服务的类型设置成 LoadBalance：NodePort类型的一种扩展，这使得服务可以通过一个专用的负载均衡器来访问，这是由 Kubernetes 中正在运行的云基础设施提供的。负载均衡器将流量重定向到跨所有节点的节点端口。客户端通过负载均衡器的 IP 连接到服务。</span><br><span class="line">+ 创建一个 Ingress 资源，这是一个完全不同的机制，通过一个 IP 地址公开多个服务。它运行在 HTTP 层（网络协议第 7 层）上，因此可以提供比工作在第 4 层的服务更多的功能。</span><br><span class="line"></span><br><span class="line"># 4.1. 使用 NodePort 类型的服务</span><br><span class="line"></span><br><span class="line">创建 NodePort 类型的服务：</span><br></pre></td></tr></table></figure></li></ul><h1 id="kubia-svc-nodeport-yaml"><a href="#kubia-svc-nodeport-yaml" class="headerlink" title="kubia-svc-nodeport.yaml"></a>kubia-svc-nodeport.yaml</h1><p>apiVersion: v1<br>kind: Service<br>metadata:<br>  name: kubia-nodeport<br>spec:<br>  type: NodePort # NodePort 类型<br>  ports:</p><ul><li>port: 80 # 服务集群 IP 的端口号<br>targetPort: 8080 # 背后 pod 的目标端口号<br>nodePort: 30123 # 通过集群节点的 30123 端口可以访问该服务，如果没有指定则随机分配<br>selector:<br>app: kubia<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">```kubectl create -f kubia-svc-nodeport.yaml</span><br></pre></td></tr></table></figure></li></ul><p>查看服务：</p><figure class="highlight plain"><figcaption><span>get svc kubia-nodeport```</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">因为我们使用的 Minikube，可以运行下面命令访问 NodePort 服务：让客户端发现</span><br><span class="line"></span><br><span class="line">```minikube service kubia-nodeport</span><br></pre></td></tr></table></figure><h1 id="4-2-通过负载均衡器将服务暴露出来"><a href="#4-2-通过负载均衡器将服务暴露出来" class="headerlink" title="4.2. 通过负载均衡器将服务暴露出来"></a>4.2. 通过负载均衡器将服务暴露出来</h1><p>在云提供商上运行的 Kubernetes 集群通常支持从云基础架构自动提供负载平衡器。所有需要做的就是设置服务的类型为 Load Badancer 而不是 NodePort。 </p><p>创建 LoadBalance 服务：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"># kubia-svc-loadbalancer.yaml</span><br><span class="line"></span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: Service</span><br><span class="line">metadata:</span><br><span class="line">  name: kubia-loadbalancer</span><br><span class="line">spec:</span><br><span class="line">  type: LoadBalancer</span><br><span class="line">  ports:</span><br><span class="line">  - port: 80</span><br><span class="line">    targetPort: 8080</span><br><span class="line">  selector:</span><br><span class="line">    app: kubia</span><br></pre></td></tr></table></figure><p>没有指定端口则随机分配一个端口</p><figure class="highlight plain"><figcaption><span>create -f kubia-svc-loadbalancer.yaml```</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">创建服务后，云基础架构需要一段时间才能创建负载均衡器并将其 IP 地址写入服务对象。完成之后 IP 地址将被列为服务的外部 IP 地址：</span><br><span class="line"></span><br><span class="line">```kubectl get svc kubia-loadbalancer</span><br></pre></td></tr></table></figure><h2 id="4-3-通过-Ingress-暴露服务"><a href="#4-3-通过-Ingress-暴露服务" class="headerlink" title="4.3. 通过 Ingress 暴露服务"></a>4.3. 通过 Ingress 暴露服务</h2><p>为什么需要 Ingress：一个重要的原因是每个 LoadBalancer 服务都需要自己的负载均衡器，以及独有的公有 IP 地址，而 Ingress 只需要一个公网 IP 就能为许多服务提供访问。当客户端向 Ingress 发送 HTTP 请求时，Ingress 会根据请求的主机名和路径决定请求转发到的服务。</p><p>Ingress 在网络栈 (HTTP) 的应用层操作，并且可以提供一些服务不能实现的功能，诸如基于 cookie 的会话亲和性 (session affinity) 等功能。</p><p>启用 Ingress 组件：</p><p><code>minikube addons enable ingress</code></p><p>因为 minikube 启动参数添加了 –driver=none 参数，不支持 Ingress 后续暂略。。。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;服务是一种为一组功能相同的 pod 提供单一不变的接入点的资源。当服务存在时，它的 IP 地址和端口不会改变。客户端通过 IP 地址和端口号建立连接，这些连接会被路由到提供该服务的任意一个 pod 上。通过这种方式，客户端不需要知道每个单独的提供服务的 pod 的地址，这样
      
    
    </summary>
    
      <category term="IT" scheme="http://victor.karonda.com/categories/IT/"/>
    
    
      <category term="Kubernetes" scheme="http://victor.karonda.com/tags/Kubernetes/"/>
    
  </entry>
  
  <entry>
    <title>k8s (三) 副本机制和其他控制器：部署托管的 pod</title>
    <link href="http://victor.karonda.com/2021/01/2120-k8s-3/"/>
    <id>http://victor.karonda.com/2021/01/2120-k8s-3/</id>
    <published>2021-01-18T05:00:00.000Z</published>
    <updated>2021-01-18T05:00:00.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="一、存活探针"><a href="#一、存活探针" class="headerlink" title="一、存活探针"></a>一、存活探针</h1><p>Kubernetes 可以通过存活探针(liveness probe)检查容器是否还在运行。 可以为 pod 中的每个容器单独指定存活探针。如果探测失败，Kubernetes 将定期执行探针并重新启动容器。Kubernetes 有以下三种探测容器的机制：</p><ul><li>HTTP GET 探针：对容器的 IP 地址执行 HTTP GET 请求。如果探测器收到响应，并且响应状态码不代表错误（响应状态码是2xx或3xx),则认为探测成功。如果服务器返回错误响应状态码或者根本没有响应，那么探测就被认为是失败的，容器将被重新启动。</li><li>TCP套接字探针：尝试与容器指定端口建立 TCP 连接。如果连接成功建立，则探测成功。否则，容器重新启动。</li><li>Exec探针：在容器内执行任意命令，并检查命令的退出状态码。如果状态码是 0 则探测成功。所有其他状态码都被认为失败。</li></ul><h2 id="1-1-创建基于-HTTP-的存活探针"><a href="#1-1-创建基于-HTTP-的存活探针" class="headerlink" title="1.1. 创建基于 HTTP 的存活探针"></a>1.1. 创建基于 HTTP 的存活探针</h2><p>将存活探针添加到 pod (kubia-liveness-probe.yaml)：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: v1</span><br><span class="line">kind: Pod</span><br><span class="line">metadata:</span><br><span class="line">  name: kubia-liveness</span><br><span class="line">spec:</span><br><span class="line">  containers:</span><br><span class="line">  - image: luksa/kubia-unhealthy</span><br><span class="line">    name: kubia</span><br><span class="line">    livenessProbe:</span><br><span class="line">      httpGet:</span><br><span class="line">        path: /</span><br><span class="line">        port: 8080</span><br><span class="line">      initialDelaySeconds: 15 # 等待 15 秒后才进行第一次探测</span><br></pre></td></tr></table></figure><p>luksa/kubia-unhealthy 这个镜像是为了演示存活探针：在第五个请求之后，返回 HTTP 状态码 500：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">const http = require(&apos;http&apos;);</span><br><span class="line">const os = require(&apos;os&apos;);</span><br><span class="line"></span><br><span class="line">console.log(&quot;Kubia server starting...&quot;);</span><br><span class="line"></span><br><span class="line">var requestCount = 0;</span><br><span class="line"></span><br><span class="line">var handler = function(request, response) &#123;</span><br><span class="line">  console.log(&quot;Received request from &quot; + request.connection.remoteAddress);</span><br><span class="line">  requestCount++;</span><br><span class="line">  if (requestCount &gt; 5) &#123;</span><br><span class="line">    response.writeHead(500);</span><br><span class="line">    response.end(&quot;I&apos;m not well. Please restart me!&quot;);</span><br><span class="line">    return;</span><br><span class="line">  &#125;</span><br><span class="line">  response.writeHead(200);</span><br><span class="line">  response.end(&quot;You&apos;ve hit &quot; + os.hostname() + &quot;\n&quot;);</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line">var www = http.createServer(handler);</span><br><span class="line">www.listen(8080);</span><br></pre></td></tr></table></figure><h1 id="1-2-使用存活探针"><a href="#1-2-使用存活探针" class="headerlink" title="1.2. 使用存活探针"></a>1.2. 使用存活探针</h1><p>创建 pod:</p><figure class="highlight plain"><figcaption><span>create -f kubia-liveness-probe.yaml```</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">查看 pod：</span><br><span class="line"></span><br><span class="line">```kubectl get pod kubia-liveness</span><br></pre></td></tr></table></figure><p>容器启动后，多次执行查看命令，可以看到 RESTARTS &gt; 1</p><p>查看 pod 重启原因：</p><figure class="highlight plain"><figcaption><span>describe pod kubia-liveness```</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"># 二、 ReplicaSet</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">我们在前面创建的基本都是未托管的 pod，可以使用控制器创建托管的 pod，可以保证 pod 不管因任何原因消失，都会自动创建替代 pod。最初 ReplicationController 是用于复制和在异常时重新调度节点的唯一组件， 后来又引入了 ReplicaSet, 而 ReplicationController 最终也将被弃用。</span><br><span class="line"></span><br><span class="line">注：通常我们不会直接创建 ReplicaSet 或 ReplicationController，而是在创建更高层级的 Deployment 资源时自动创建他们。</span><br><span class="line"></span><br><span class="line">## 2.1. 创建 RelicaSet</span><br><span class="line"></span><br><span class="line">kubia-replicaset.yaml：</span><br></pre></td></tr></table></figure><p>apiVersion: apps/v1 # 不是 v1 版本 API 的一部分，属于 apps API 组的 v1 版本<br>kind: ReplicaSet<br>metadata:<br>  name: kubia<br>spec:<br>  replicas: 3<br>  selector:<br>    matchLabels:<br>      app: kubia # matchLabels 选择器<br>  template:<br>    metadata:<br>      labels:<br>        app: kubia # 标签<br>    spec:<br>      containers:</p><pre><code>- name: kubia  image: luksa/kubia</code></pre><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">创建：</span><br><span class="line"></span><br><span class="line">```kubectl create -f kubia-replicaset.yaml</span><br></pre></td></tr></table></figure><p>查看：</p><figure class="highlight plain"><figcaption><span>get rs # rs 是 replicaset 的简写```</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">删除：</span><br><span class="line"></span><br><span class="line">```kubectl delete rs kubia</span><br></pre></td></tr></table></figure><h2 id="2-2-ReplicaSet-的标签选择器"><a href="#2-2-ReplicaSet-的标签选择器" class="headerlink" title="2.2. ReplicaSet 的标签选择器"></a>2.2. ReplicaSet 的标签选择器</h2><ul><li>In: Label 的值必须与其中一个指定的 values 匹配。</li><li>NotIn: Label 的值与任何指定的 values 不匹配。</li><li>Exists: pod 必须包含一个指定名称的标签。使用此运算符时，不应指定 values 字段。</li><li>DoesNotExist: pod 不得包含有指定名称的标签。values属性不得指定。</li></ul><p>如果指定了多个表达式，则所有这些表达式都必须为 true 才能使选择器与 pod 匹配。如果同时指定 matchLabels 和 matchExpressions, 则所有标签都必须匹配，并且所有表达式必须计算为 true 以使该 pod 与选择器匹配。</p><p>示例：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">... ...</span><br><span class="line">  selector:</span><br><span class="line">    matchExpressions:</span><br><span class="line">      - key: app</span><br><span class="line">        operator: In</span><br><span class="line">        values:</span><br><span class="line">         - kubia</span><br><span class="line">... ...</span><br></pre></td></tr></table></figure><h1 id="三、DaemonSet"><a href="#三、DaemonSet" class="headerlink" title="三、DaemonSet"></a>三、DaemonSet</h1><p>Replicationcontroller 和 ReplicaSet 都用于在 Kubernetes 集群上运行部署特定数量的 pod（随机分布在集群上）。DaemonSet 则可以实现在每个节点或者指定的节点上运行一个 pod。适用于比如 pod 执行系统级别的与基础结构相关的操作，例如，希望在每个节点上运行日志收集器和资源监控器；另一个典型的例子是 Kubernetes 自己的 kube-proxy 进程，它需要运行在所有节点上才能使服务工作。</p><p>DaemonSet 配置示例：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: apps/v1</span><br><span class="line">kind: DaemonSet</span><br><span class="line">metadata:</span><br><span class="line">  name: ssd-monitor</span><br><span class="line">spec:</span><br><span class="line">  selector:</span><br><span class="line">    matchLabels:</span><br><span class="line">      app: ssd-monitor</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      labels:</span><br><span class="line">        app: ssd-monitor</span><br><span class="line">    spec:</span><br><span class="line">      nodeSelector:</span><br><span class="line">        disk: ssd # 选择标签 disk=ssd 的 node</span><br><span class="line">      containers:</span><br><span class="line">      - name: main</span><br><span class="line">        image: luksa/ssd-monitor</span><br></pre></td></tr></table></figure><h1 id="四、执行单个任务的-pod"><a href="#四、执行单个任务的-pod" class="headerlink" title="四、执行单个任务的 pod"></a>四、执行单个任务的 pod</h1><h2 id="4-1-创建-job"><a href="#4-1-创建-job" class="headerlink" title="4.1. 创建 job"></a>4.1. 创建 job</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: batch/v1 # Job 属于 batch API 组</span><br><span class="line">kind: Job</span><br><span class="line">metadata:</span><br><span class="line">  name: batch-job</span><br><span class="line">spec:</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      labels:</span><br><span class="line">        app: batch-job</span><br><span class="line">    spec:</span><br><span class="line">      restartPolicy: OnFailure # Job 不能使用 Always 为默认的重启启动策略，应该为 OnFailure 或 Never</span><br><span class="line">      containers:</span><br><span class="line">      - name: main</span><br><span class="line">        image: luksa/batch-job</span><br></pre></td></tr></table></figure><p>查看：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">kubectl get jobs</span><br><span class="line"></span><br><span class="line">kubectl get pods</span><br></pre></td></tr></table></figure><h2 id="4-2-在-Job-中运行多个-pod-实例"><a href="#4-2-在-Job-中运行多个-pod-实例" class="headerlink" title="4.2. 在 Job 中运行多个 pod 实例"></a>4.2. 在 Job 中运行多个 pod 实例</h2><p>顺序运行：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">... ...</span><br><span class="line">metadata:</span><br><span class="line">  name: multi-completion-batch-job</span><br><span class="line">spec:</span><br><span class="line">  completions: 5 # 此作业顺序运行 5 个 pod</span><br><span class="line">... ...</span><br></pre></td></tr></table></figure><p>并行运行：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">... ...</span><br><span class="line">metadata:</span><br><span class="line">  name: multi-completion-batch-job</span><br><span class="line">spec:</span><br><span class="line">  completions: 5 # 这项任务必须确保 5 个 pod 成功完成</span><br><span class="line">  parallelism: 2 # 最多 2 个 pod 可以并行运行</span><br><span class="line">... ...</span><br></pre></td></tr></table></figure><p>可以在 job 运行的时候 更改 parallelism 属性，缩放 job：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl scale job multi-completion-batch-job --replicas 3</span><br></pre></td></tr></table></figure><p>其他属性：</p><ul><li>activeDeadlineSeconds：限制 pod的时间，如果 pod 运行时间超过此时间，系统将尝试终止 pod, 并将 Job 标记为失败。</li><li>spec.backoffLimit：Job 在被标记为失败之前重试的次数，默认值为 6</li></ul><h2 id="4-3-CronJob"><a href="#4-3-CronJob" class="headerlink" title="4.3. CronJob"></a>4.3. CronJob</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: batch/v1</span><br><span class="line">kind: CronJob</span><br><span class="line">metadata:</span><br><span class="line">  name: batch-job-every-fifteen-minutes</span><br><span class="line">spec:</span><br><span class="line">  schedule: &quot;0,15,30,45 * * * *&quot; # cron 表达式</span><br><span class="line">  jobTemplate:</span><br><span class="line">    spec:</span><br><span class="line">      template:</span><br><span class="line">        metadata:</span><br><span class="line">          labels:</span><br><span class="line">            app: periodic-batch-job</span><br><span class="line">        spec:</span><br><span class="line">          restartPolicy: OnFailure</span><br><span class="line">          containers:</span><br><span class="line">          - name: main</span><br><span class="line">            image: luksa/batch-job</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;一、存活探针&quot;&gt;&lt;a href=&quot;#一、存活探针&quot; class=&quot;headerlink&quot; title=&quot;一、存活探针&quot;&gt;&lt;/a&gt;一、存活探针&lt;/h1&gt;&lt;p&gt;Kubernetes 可以通过存活探针(liveness probe)检查容器是否还在运行。 可以为 pod
      
    
    </summary>
    
      <category term="IT" scheme="http://victor.karonda.com/categories/IT/"/>
    
    
      <category term="Kubernetes" scheme="http://victor.karonda.com/tags/Kubernetes/"/>
    
  </entry>
  
  <entry>
    <title>k8s (一) 学习环境 Kubernetes 集群搭建</title>
    <link href="http://victor.karonda.com/2021/01/2120-k8s-1/"/>
    <id>http://victor.karonda.com/2021/01/2120-k8s-1/</id>
    <published>2021-01-15T04:00:00.000Z</published>
    <updated>2021-01-15T04:00:00.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="一、安装-Docker"><a href="#一、安装-Docker" class="headerlink" title="一、安装 Docker"></a>一、安装 Docker</h1><figure class="highlight plain"><figcaption><span>-fsSL</span><a href="https://get.docker.com" target="_blank" rel="noopener">| bash -s docker --mirror Aliyun```</a></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">镜像加速（本文使用阿里云镜像）：</span><br></pre></td></tr></table></figure><h2 id="vi-etc-docker-daemon-json"><a href="#vi-etc-docker-daemon-json" class="headerlink" title="vi /etc/docker/daemon.json"></a>vi /etc/docker/daemon.json</h2><p>{“registry-mirrors”:[“https://&lt;你的ID&gt;.mirror.aliyuncs.com”]}</p><h2 id="systemctl-daemon-reload"><a href="#systemctl-daemon-reload" class="headerlink" title="systemctl daemon-reload"></a>systemctl daemon-reload</h2><h2 id="systemctl-restart-docker"><a href="#systemctl-restart-docker" class="headerlink" title="systemctl restart docker"></a>systemctl restart docker</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">&gt; 备注：本文使用的镜像为 luksa/kubia，是《Kubernetes in Action》中使用的镜像，其为一个简单的 Node.js 应用：</span><br></pre></td></tr></table></figure><p>const http = require(‘http’);<br>const os = require(‘os’);</p><p>console.log(“Kubia server starting…”);</p><p>var handler = function(request, response) {<br>console.log(“Received request form “ + request.connection.remoteAddress);<br>response.writeHead(200);<br>response.end(“You’ve hit “ + os.hostname() + “\n”);<br>};</p><p>var www = http.createServer(handler);<br><a href="http://www.listen(8080)" target="_blank" rel="noopener">www.listen(8080)</a>;<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">Dockerfile 文件的内容为：</span><br></pre></td></tr></table></figure></p><p>FROM node:7<br>ADD app.js /app.js<br>ENTRYPOINT [“node”, “app.js”]<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"># 二、配置 k8s 集群</span><br><span class="line"></span><br><span class="line">Minikube 是一个构建单节点集群的工具，是运行 Kubemetes 集群最简单、最快捷的途径</span><br><span class="line"></span><br><span class="line"># 2.1. 安装 kubectl</span><br><span class="line"></span><br><span class="line">官方给出地址是：https://storage.googleapis.com ，需要梯子才能使用，改为使用阿里云的下载地址：</span><br><span class="line"></span><br><span class="line">```curl -Lo kubectl http://kubernetes.oss-cn-hangzhou.aliyuncs.com/kubernetes-release/release/v1.20.0/bin/linux/amd64/kubectl &amp;&amp; chmod +x ./kubectl &amp;&amp; mv ./kubectl /usr/local/bin/kubectl</span><br></pre></td></tr></table></figure></p><p>验证是否成功：</p><figure class="highlight plain"><figcaption><span>version --client```</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"># 2.2. 安装 minikube</span><br><span class="line"></span><br><span class="line">同样使用阿里云的下载地址：</span><br><span class="line"></span><br><span class="line">```curl -Lo minikube http://kubernetes.oss-cn-hangzhou.aliyuncs.com/minikube/releases/v1.16.0/minikube-linux-amd64 &amp;&amp; chmod +x ./minikube &amp;&amp; mv ./minikube /usr/local/bin/minikube</span><br></pre></td></tr></table></figure><p>启动集群：</p><figure class="highlight plain"><figcaption><span>start --driver</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">查看集群（前提是已经安装了 kubectl）：</span><br><span class="line"></span><br><span class="line">```kubectl get pod -A # pod 可以缩写为 po</span><br></pre></td></tr></table></figure><blockquote><p>遇到的报错：</p></blockquote><ol><li>Sorry, Kubernetes 1.20.0 requires conntrack to be installed in root’s path</li></ol><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">## 安装 conntrack:</span><br><span class="line"></span><br><span class="line">yum install conntrack</span><br></pre></td></tr></table></figure><ol start="2"><li>/proc/sys/net/bridge/bridge-nf-call-iptables contents are not set to 1</li></ol><figure class="highlight plain"><figcaption><span>"1" >/proc/sys/net/bridge/bridge-nf-call-iptables   #/pro的配置文件根据实际环境来```</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"># 三、部署应用</span><br><span class="line"></span><br><span class="line">## 3.1. 部署应用</span><br><span class="line"></span><br><span class="line">```kubectl create deployment hello-minikube --image=luksa/kubia</span><br></pre></td></tr></table></figure><h3 id="3-1-1-pod"><a href="#3-1-1-pod" class="headerlink" title="3.1.1. pod"></a>3.1.1. pod</h3><p>一个 pod 是一组紧密相关的容器，它们总是一起运行在同一个工作节上，以及同一个 Linux 命名空间中。每个 pod 就像一个独立的逻辑机器，拥有自己的 IP、主机名、进程等，运行一个独立的应用程序。应用程序可以是单个进程，运行在单个容器中，也可以是一个主应用进程或者其他支持进程，每个进程都在自己的容器中运行一个 pod 的所有容器都运行在同一个逻辑机器上，而其他  pod 中的容器，即使运行在同个工作节点上，也会出现在不同的节点上。</p><p><img src="https://victorblog.nos-eastchina1.126.net/2120/1/pod.png" alt></p><p>可以通过下面命令查看 pod 列表：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">kubectl get pods</span><br><span class="line"></span><br><span class="line">kubectl get pods -o wide # 显示 pod 运行的 IP 和所运行的节点</span><br></pre></td></tr></table></figure><h2 id="3-2-创建服务对象"><a href="#3-2-创建服务对象" class="headerlink" title="3.2. 创建服务对象"></a>3.2. 创建服务对象</h2><p>每个 pod 都有自己的 IP 地址，但是这个地址是集群内部的，不能从集群外部访问。要让 pod 能够从外部访问，需要通过服务对象公开它，要创建一个特殊的 LoadBalancer 类型的服务。因为如果你创建一个常规服务（一个 ClusterIP 服务），比如 pod，它只能从集群内部访问。通过创建 LoadBalancer 类型的服务，将创建一个外部的负载均衡，可以通过负载均衡的公共 IP 访问 pod</p><figure class="highlight plain"><figcaption><span>expose deployment hello-minikube --type</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">可以通过下面命令查看服务列表：</span><br><span class="line"></span><br><span class="line">```kubectl get services</span><br></pre></td></tr></table></figure><p>如果执行上面的命令可以看到服务是没有外部 IP 的，可以使用下面命令为其分配端口：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">minikube service hello-minikube</span><br><span class="line"></span><br><span class="line"># 本文分配的端口为：31526</span><br></pre></td></tr></table></figure><p>也可以使用下面命令指定端口：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">kubectl port-forward service/hello-minikube 7080:8080</span><br><span class="line"></span><br><span class="line"># 可以通过 http://localhost:7080 访问</span><br></pre></td></tr></table></figure><h2 id="3-3-水平伸缩应用"><a href="#3-3-水平伸缩应用" class="headerlink" title="3.3. 水平伸缩应用"></a>3.3. 水平伸缩应用</h2><p>可以通过下面命令查看 Deployment 列表：</p><figure class="highlight plain"><figcaption><span>get deployments```</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">默认只有 1 个 pod 副本，可以增加 pod 副本的数量：</span><br><span class="line"></span><br><span class="line">```kubectl scale deployment hello-minikube --replicas 3</span><br></pre></td></tr></table></figure><p>再次执行查看 Deployment 列表命令，可以看到目标数量变成了 3（需要等待一段时间 3 个 pod 才能都启动），等 3 个 pod 都成功启动后，多次调用接口，可以看到有不同的输出：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">curl http://192.168.12.130:31526 # 31526 为本文分配的端口</span><br><span class="line"></span><br><span class="line">## You&apos;ve hit hello-minikube-6895494d6d-wsfmx</span><br><span class="line">## You&apos;ve hit hello-minikube-6895494d6d-cbsnz</span><br><span class="line">## You&apos;ve hit hello-minikube-6895494d6d-rvgvw</span><br></pre></td></tr></table></figure><blockquote><p>参考：</p></blockquote><ol><li>《Kubernetes in Action》</li><li><a href="https://kubernetes.io/docs/tasks/tools/install-kubectl/" target="_blank" rel="noopener">Install and Set Up kubectl</a></li><li><a href="https://minikube.sigs.k8s.io/docs/start/" target="_blank" rel="noopener">minikube start</a></li></ol>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;一、安装-Docker&quot;&gt;&lt;a href=&quot;#一、安装-Docker&quot; class=&quot;headerlink&quot; title=&quot;一、安装 Docker&quot;&gt;&lt;/a&gt;一、安装 Docker&lt;/h1&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;figc
      
    
    </summary>
    
      <category term="IT" scheme="http://victor.karonda.com/categories/IT/"/>
    
    
      <category term="Docker" scheme="http://victor.karonda.com/tags/Docker/"/>
    
      <category term="Kubernetes" scheme="http://victor.karonda.com/tags/Kubernetes/"/>
    
  </entry>
  
  <entry>
    <title>Prometheus 使用之 node exporter</title>
    <link href="http://victor.karonda.com/2020/10/2119-prometheus-node/"/>
    <id>http://victor.karonda.com/2020/10/2119-prometheus-node/</id>
    <published>2020-10-30T10:00:00.000Z</published>
    <updated>2020-10-30T10:00:00.000Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>本文使用的 Prometheus 版本为 2.22.0，node exporter 版本为 1.0.1；部署在 Linux 服务器</p></blockquote><p>Prometheus 是开源的监控报警系统和时序列数据库 (TSDB)；node exporter 用来监控服务器CPU、内存、磁盘、I/O等信息</p><h1 id="一、node-exporter"><a href="#一、node-exporter" class="headerlink" title="一、node exporter"></a>一、node exporter</h1><p>node exporter 下载地址：<a href="https://prometheus.io/download/#node_exporter，下载" target="_blank" rel="noopener">https://prometheus.io/download/#node_exporter，下载</a> node_exporter-1.0.1.linux-amd64.tar.gz</p><p>执行命令：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">tar -xzvf node_exporter-1.0.1.linux-amd64.tar.gz</span><br><span class="line"></span><br><span class="line">nohup ./xx/node_exporter-1.0.1.linux-amd64/node_exporter &gt;/dev/null 2&gt;&amp;1 &amp;</span><br><span class="line">`</span><br></pre></td></tr></table></figure><p>其中 xx 为自定义目录</p><p>默认端口为 9100</p><h1 id="二、Prometheus"><a href="#二、Prometheus" class="headerlink" title="二、Prometheus"></a>二、Prometheus</h1><p>Prometheus 下载地址：<a href="https://prometheus.io/download/#prometheus，下载" target="_blank" rel="noopener">https://prometheus.io/download/#prometheus，下载</a> prometheus-2.22.0.linux-amd64.tar.gz</p><p>执行命令：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tar -xzvf prometheus-2.22.0.linux-amd64.tar.gz</span><br></pre></td></tr></table></figure><p>在 prometheus.yml 文件末尾添加：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">scrape_configs:</span><br><span class="line">  ... ...</span><br><span class="line">  - job_name: &apos;node&apos;</span><br><span class="line">    static_configs:</span><br><span class="line">    - targets: [&apos;localhost:9100&apos;]</span><br></pre></td></tr></table></figure><p>启动 Prometheus：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">nohup /xx/prometheus-2.22.0.linux-amd64/prometheus \</span><br><span class="line">--config.file=/xx/prometheus-2.22.0.linux-amd64/prometheus.yml \</span><br><span class="line">--storage.tsdb.path=/xx/data/prometheus \</span><br><span class="line">--storage.tsdb.retention=7d \</span><br><span class="line">&gt;/dev/null 2&gt;&amp;1 &amp;</span><br></pre></td></tr></table></figure><p>其中 xx 为自定义目录</p><p>默认端口为 9090</p><h1 id="三、在-Grafana-中添加数据源与看板"><a href="#三、在-Grafana-中添加数据源与看板" class="headerlink" title="三、在 Grafana 中添加数据源与看板"></a>三、在 Grafana 中添加数据源与看板</h1><h2 id="3-1-添加数据源"><a href="#3-1-添加数据源" class="headerlink" title="3.1. 添加数据源"></a>3.1. 添加数据源</h2><ol><li>登录 Grafana，在 Configuration &gt; Data Sources 点击 “Add data source” 按钮，选中 Prometheus</li><li>URL 填入 <a href="http://localhost:9090，并保存" target="_blank" rel="noopener">http://localhost:9090，并保存</a></li></ol><h2 id="3-2-添加看板"><a href="#3-2-添加看板" class="headerlink" title="3.2. 添加看板"></a>3.2. 添加看板</h2><ol><li>在 “+” 点击 “Import”</li><li>在 “Import via grafana.com” 下面的输入框，输入 8919，然后点击”Load”按钮</li><li>在 Dashboards 即可看到面板列表</li></ol><p>关于 8919 的解释：</p><p>Grafana 官网有已经可以直接使用的 dashboard，地址：<a href="https://grafana.com/grafana/dashboards" target="_blank" rel="noopener">https://grafana.com/grafana/dashboards</a> 输入对应的 id 即可添加</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;blockquote&gt;
&lt;p&gt;本文使用的 Prometheus 版本为 2.22.0，node exporter 版本为 1.0.1；部署在 Linux 服务器&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Prometheus 是开源的监控报警系统和时序列数据库 (TSDB)；n
      
    
    </summary>
    
      <category term="IT" scheme="http://victor.karonda.com/categories/IT/"/>
    
    
      <category term="Grafana" scheme="http://victor.karonda.com/tags/Grafana/"/>
    
      <category term="Prometheus" scheme="http://victor.karonda.com/tags/Prometheus/"/>
    
      <category term="node exporter" scheme="http://victor.karonda.com/tags/node-exporter/"/>
    
  </entry>
  
  <entry>
    <title>日志聚合工具之 Loki</title>
    <link href="http://victor.karonda.com/2020/09/2118-loki/"/>
    <id>http://victor.karonda.com/2020/09/2118-loki/</id>
    <published>2020-09-27T12:00:00.000Z</published>
    <updated>2020-09-17T12:00:00.000Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>本文使用的 Loki 和 Promtail 版本为 1.6.1，Grafana 版本为 7.2.0；部署在 Linux 服务器</p></blockquote><p>Loki 负责日志的存储和查询；Promtail 负责日志的采集并推送给 Loki；Grafana 负责日志展示</p><h1 id="一、Loki"><a href="#一、Loki" class="headerlink" title="一、Loki"></a>一、Loki</h1><p>Loki 下载地址：<a href="https://github.com/grafana/loki/releases，下载" target="_blank" rel="noopener">https://github.com/grafana/loki/releases，下载</a> loki-linux-amd64.zip</p><p>在 Loki 的源码里找到对应版本的配置文件：/cmd/loki/loki-local-config.yaml，文件内容为：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line">auth_enabled: false</span><br><span class="line"></span><br><span class="line">server:</span><br><span class="line">  http_listen_port: 3100</span><br><span class="line"></span><br><span class="line">ingester:</span><br><span class="line">  lifecycler:</span><br><span class="line">    address: 127.0.0.1</span><br><span class="line">    ring:</span><br><span class="line">      kvstore:</span><br><span class="line">        store: inmemory</span><br><span class="line">      replication_factor: 1</span><br><span class="line">    final_sleep: 0s</span><br><span class="line">  chunk_idle_period: 5m</span><br><span class="line">  chunk_retain_period: 30s</span><br><span class="line">  max_transfer_retries: 0</span><br><span class="line"></span><br><span class="line">schema_config:</span><br><span class="line">  configs:</span><br><span class="line">    - from: 2018-04-15</span><br><span class="line">      store: boltdb</span><br><span class="line">      object_store: filesystem</span><br><span class="line">      schema: v11</span><br><span class="line">      index:</span><br><span class="line">        prefix: index_</span><br><span class="line">        period: 168h</span><br><span class="line"></span><br><span class="line">storage_config:</span><br><span class="line">  boltdb:</span><br><span class="line">    directory: /tmp/loki/index</span><br><span class="line"></span><br><span class="line">  filesystem:</span><br><span class="line">    directory: /tmp/loki/chunks</span><br><span class="line"></span><br><span class="line">limits_config:</span><br><span class="line">  enforce_metric_name: false</span><br><span class="line">  reject_old_samples: true</span><br><span class="line">  reject_old_samples_max_age: 168h</span><br><span class="line"></span><br><span class="line">chunk_store_config:</span><br><span class="line">  max_look_back_period: 0s</span><br><span class="line"></span><br><span class="line">table_manager:</span><br><span class="line">  retention_deletes_enabled: false</span><br><span class="line">  retention_period: 0s</span><br></pre></td></tr></table></figure><p>根据具体情况决定是否修改上述配置，然后执行以下命令：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">unzip loki-linux-amd64.zip</span><br><span class="line"></span><br><span class="line">nohup ./loki-linux-amd64 -config.file=loki-local-config.yaml &gt;/dev/null 2&gt;&amp;1 &amp;</span><br></pre></td></tr></table></figure><h1 id="二、Promtail"><a href="#二、Promtail" class="headerlink" title="二、Promtail"></a>二、Promtail</h1><p>Promtail 下载地址：<a href="https://github.com/grafana/loki/releases，下载" target="_blank" rel="noopener">https://github.com/grafana/loki/releases，下载</a> promtail-linux-amd64.zip</p><p>在 Loki 的源码里找到对应版本的配置文件：/cmd/promtail/promtail-local-config.yaml，文件内容为：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">server:</span><br><span class="line">  http_listen_port: 9080</span><br><span class="line">  grpc_listen_port: 0</span><br><span class="line"></span><br><span class="line">positions:</span><br><span class="line">  filename: /tmp/positions.yaml</span><br><span class="line"></span><br><span class="line">clients:</span><br><span class="line">  - url: http://localhost:3100/loki/api/v1/push</span><br><span class="line"></span><br><span class="line">scrape_configs:</span><br><span class="line">- job_name: system</span><br><span class="line">  static_configs:</span><br><span class="line">  - targets:</span><br><span class="line">      - localhost</span><br><span class="line">    labels:</span><br><span class="line">      job: varlogs</span><br><span class="line">      __path__: /var/log/*log</span><br></pre></td></tr></table></figure><p>根据具体情况决定是否修改上述配置或者添加 job，然后执行以下命令：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">unzip promtail-linux-amd64.zip</span><br><span class="line"></span><br><span class="line">nohup ./promtail-linux-amd64 -config.file=promtail-local-config.yaml &gt;/dev/null 2&gt;&amp;1 &amp;</span><br></pre></td></tr></table></figure><h1 id="三、Grafana"><a href="#三、Grafana" class="headerlink" title="三、Grafana"></a>三、Grafana</h1><h2 id="3-1-下载并启动"><a href="#3-1-下载并启动" class="headerlink" title="3.1. 下载并启动"></a>3.1. 下载并启动</h2><p>如果之前没有安装过 Grafana，需要先下载安装，下载地址：<a href="https://grafana.com/grafana/download" target="_blank" rel="noopener">https://grafana.com/grafana/download</a></p><p>执行以下命令：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">tar -xzvf grafana-7.2.0.linux-amd64.tar.gz</span><br><span class="line"></span><br><span class="line">cd grafana-7.2.0</span><br><span class="line"></span><br><span class="line">nohup ./bin/grafana-server &gt;/dev/null 2&gt;&amp;1 &amp;</span><br></pre></td></tr></table></figure><p>如果不是在 grafana 所在目录执行运行命令需要添加参数，如：-homepath /xx/grafana-7.2.0</p><p>其中 xx 为自定义目录</p><p>默认端口为 3000，用户名密码均为 admin</p><h2 id="3-2-配置"><a href="#3-2-配置" class="headerlink" title="3.2. 配置"></a>3.2. 配置</h2><ol><li>登录 Grafana，在 Configuration &gt; Data Sources 点击 “Add data source” 按钮，选中 Loki</li><li>URL 填入 <a href="http://localhost:3100，并保存" target="_blank" rel="noopener">http://localhost:3100，并保存</a></li><li>在 Explore 中选中上面添加的 Loki 数据源 既可以看到日志信息</li></ol>]]></content>
    
    <summary type="html">
    
      
      
        &lt;blockquote&gt;
&lt;p&gt;本文使用的 Loki 和 Promtail 版本为 1.6.1，Grafana 版本为 7.2.0；部署在 Linux 服务器&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Loki 负责日志的存储和查询；Promtail 负责日志的采集并推送给 Lo
      
    
    </summary>
    
      <category term="IT" scheme="http://victor.karonda.com/categories/IT/"/>
    
    
      <category term="Loki" scheme="http://victor.karonda.com/tags/Loki/"/>
    
      <category term="Promtail" scheme="http://victor.karonda.com/tags/Promtail/"/>
    
      <category term="Grafana" scheme="http://victor.karonda.com/tags/Grafana/"/>
    
  </entry>
  
  <entry>
    <title>在 Spring Boot 配置 Kafka 安全认证</title>
    <link href="http://victor.karonda.com/2020/09/2117-spring-boot-kafka-security/"/>
    <id>http://victor.karonda.com/2020/09/2117-spring-boot-kafka-security/</id>
    <published>2020-09-03T12:00:00.000Z</published>
    <updated>2020-09-03T12:00:00.000Z</updated>
    
    <content type="html"><![CDATA[<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">spring:</span><br><span class="line">  kafka:</span><br><span class="line">    bootstrap-servers: IP:端口</span><br><span class="line">    listener:</span><br><span class="line">      missing-topics-fatal: false</span><br><span class="line">    properties:</span><br><span class="line">      sasl:</span><br><span class="line">        mechanism: PLAIN</span><br><span class="line">        jaas:</span><br><span class="line">          config: &apos;org.apache.kafka.common.security.plain.PlainLoginModule required username=&quot;用户名&quot; password=&quot;密码&quot;;&apos;</span><br><span class="line">      security:</span><br><span class="line">        protocol: SASL_PLAINTEXT</span><br><span class="line">    producer:</span><br><span class="line">      key-serializer: org.apache.kafka.common.serialization.StringSerializer</span><br><span class="line">      value-serializer: org.apache.kafka.common.serialization.StringSerializer</span><br><span class="line">    consumer:</span><br><span class="line">      group-id: test_consumer_group</span><br><span class="line">      enable-auto-commit: true</span><br><span class="line">      auto-commit-interval: 1000</span><br><span class="line">      key-deserializer: org.apache.kafka.common.serialization.StringDeserializer</span><br><span class="line">      value-deserializer: org.apache.kafka.common.serialization.StringDeserializer</span><br></pre></td></tr></table></figure><p>参考：<a href="https://blog.csdn.net/u010637366/article/details/108142216" target="_blank" rel="noopener">SpringBoot 支持Kafka安全认证 SASL/PLAINTEXT，账号密码认证</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class
      
    
    </summary>
    
      <category term="IT" scheme="http://victor.karonda.com/categories/IT/"/>
    
    
      <category term="Spring Boot" scheme="http://victor.karonda.com/tags/Spring-Boot/"/>
    
      <category term="Kafka" scheme="http://victor.karonda.com/tags/Kafka/"/>
    
  </entry>
  
  <entry>
    <title>Java MQTT 客户端之 Paho</title>
    <link href="http://victor.karonda.com/2020/07/2116-mqtt-paho/"/>
    <id>http://victor.karonda.com/2020/07/2116-mqtt-paho/</id>
    <published>2020-07-17T03:00:00.000Z</published>
    <updated>2020-07-17T03:00:00.000Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>Paho 自动重连后订阅的主题会清空，所以需要实现 MqttCallbackExtended 接口，在 connectComplete 方法添加订阅主题；而不是实现 MqttCallback 接口</p></blockquote><h1 id="一、添加引用"><a href="#一、添加引用" class="headerlink" title="一、添加引用"></a>一、添加引用</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">&lt;dependency&gt;</span><br><span class="line">    &lt;groupId&gt;org.eclipse.paho&lt;/groupId&gt;</span><br><span class="line">    &lt;artifactId&gt;org.eclipse.paho.client.mqttv3&lt;/artifactId&gt;</span><br><span class="line">    &lt;version&gt;1.2.5&lt;/version&gt;</span><br><span class="line">&lt;/dependency&gt;</span><br></pre></td></tr></table></figure><h1 id="二、添加配置"><a href="#二、添加配置" class="headerlink" title="二、添加配置"></a>二、添加配置</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">mqtt:</span><br><span class="line">  client:</span><br><span class="line">    username: admin</span><br><span class="line">    password: public</span><br><span class="line">    serverURI: tcp://192.168.137.101:1883</span><br><span class="line">    clientId: paho_$&#123;random.int[1000,9999]&#125;</span><br><span class="line">    keepAliveInterval: 120</span><br><span class="line">    connectionTimeout: 30</span><br><span class="line">  producer:</span><br><span class="line">    defaultQos: 1</span><br><span class="line">    defaultRetained: true</span><br><span class="line">    defaultTopic: topic/test1</span><br><span class="line">  consumer:</span><br><span class="line">    consumerTopics: topic/test2,topic/test3</span><br></pre></td></tr></table></figure><h1 id="三、代码"><a href="#三、代码" class="headerlink" title="三、代码"></a>三、代码</h1><h2 id="3-1-客户端"><a href="#3-1-客户端" class="headerlink" title="3.1.客户端"></a>3.1.客户端</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br></pre></td><td class="code"><pre><span class="line">@Configuration</span><br><span class="line">public class MqttConfig &#123;</span><br><span class="line">    @Value(&quot;$&#123;mqtt.client.username&#125;&quot;)</span><br><span class="line">    private String username;</span><br><span class="line">    @Value(&quot;$&#123;mqtt.client.password&#125;&quot;)</span><br><span class="line">    private String password;</span><br><span class="line">    @Value(&quot;$&#123;mqtt.client.serverURI&#125;&quot;)</span><br><span class="line">    private String serverURI;</span><br><span class="line">    @Value(&quot;$&#123;mqtt.client.clientId&#125;&quot;)</span><br><span class="line">    private String clientId;</span><br><span class="line">    @Value(&quot;$&#123;mqtt.client.keepAliveInterval&#125;&quot;)</span><br><span class="line">    private int keepAliveInterval;</span><br><span class="line">    @Value(&quot;$&#123;mqtt.client.connectionTimeout&#125;&quot;)</span><br><span class="line">    private int connectionTimeout;</span><br><span class="line"></span><br><span class="line">    @Autowired</span><br><span class="line">    private MyMqttCallback myMqttCallback;</span><br><span class="line"></span><br><span class="line">    @Bean</span><br><span class="line">    public MqttClient mqttClient() &#123;</span><br><span class="line">        try &#123;</span><br><span class="line">            MqttClientPersistence persistence = mqttClientPersistence();</span><br><span class="line">            MqttClient client = new MqttClient(serverURI, clientId, persistence);</span><br><span class="line"></span><br><span class="line">            myMqttCallback.setMqttClient(client);</span><br><span class="line">            client.setCallback(myMqttCallback);</span><br><span class="line"></span><br><span class="line">            client.connect(mqttConnectOptions());</span><br><span class="line">//            client.subscribe(subTopic);</span><br><span class="line"></span><br><span class="line">            return client;</span><br><span class="line">        &#125; catch (MqttException e) &#123;</span><br><span class="line">            System.out.println(e.getMessage());</span><br><span class="line">            return null;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    @Bean</span><br><span class="line">    public MqttConnectOptions mqttConnectOptions() &#123;</span><br><span class="line">        MqttConnectOptions options = new MqttConnectOptions();</span><br><span class="line">        options.setUserName(username);</span><br><span class="line">        options.setPassword(password.toCharArray());</span><br><span class="line">        options.setCleanSession(true);</span><br><span class="line">        options.setAutomaticReconnect(true);</span><br><span class="line">        options.setConnectionTimeout(connectionTimeout);</span><br><span class="line">        options.setKeepAliveInterval(keepAliveInterval);</span><br><span class="line"></span><br><span class="line">        return options;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    public MqttClientPersistence mqttClientPersistence() &#123;</span><br><span class="line">        return new MemoryPersistence();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="3-2-订阅者"><a href="#3-2-订阅者" class="headerlink" title="3.2.订阅者"></a>3.2.订阅者</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line">@Component</span><br><span class="line">public class MyMqttCallback implements MqttCallbackExtended &#123;</span><br><span class="line"></span><br><span class="line">    @Value(&quot;$&#123;mqtt.consumer.consumerTopics&#125;&quot;)</span><br><span class="line">    private String[] consumerTopics;</span><br><span class="line"></span><br><span class="line">    @Autowired</span><br><span class="line">    private MqttService mqttService;</span><br><span class="line"></span><br><span class="line">    private MqttClient mqttClient;</span><br><span class="line"></span><br><span class="line">    @Override</span><br><span class="line">    public void connectionLost(Throwable throwable) &#123;</span><br><span class="line">        System.out.println(&quot;连接断开&quot;);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    @Override</span><br><span class="line">    public void messageArrived(String topic, MqttMessage message) throws Exception &#123;</span><br><span class="line">        mqttService.message(topic, message);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    @Override</span><br><span class="line">    public void deliveryComplete(IMqttDeliveryToken iMqttDeliveryToken) &#123;</span><br><span class="line">        System.out.println(&quot;deliveryComplete---------&quot; + iMqttDeliveryToken.isComplete());</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    @Override</span><br><span class="line">    public void connectComplete(boolean b, String s) &#123;</span><br><span class="line">        try &#123;</span><br><span class="line">            mqttClient.subscribe(consumerTopics);</span><br><span class="line">        &#125; catch (MqttException e) &#123;</span><br><span class="line">            System.out.println(e.getMessage());</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    public void setMqttClient(MqttClient mqttClient) &#123;</span><br><span class="line">        this.mqttClient = mqttClient;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="3-3-发布者"><a href="#3-3-发布者" class="headerlink" title="3.3.发布者"></a>3.3.发布者</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line">@Component</span><br><span class="line">public class MqttProducer &#123;</span><br><span class="line"></span><br><span class="line">    @Value(&quot;$&#123;mqtt.producer.defaultQos&#125;&quot;)</span><br><span class="line">    private int defaultProducerQos;</span><br><span class="line">    @Value(&quot;$&#123;mqtt.producer.defaultRetained&#125;&quot;)</span><br><span class="line">    private boolean defaultRetained;</span><br><span class="line">    @Value(&quot;$&#123;mqtt.producer.defaultTopic&#125;&quot;)</span><br><span class="line">    private String defaultTopic;</span><br><span class="line"></span><br><span class="line">    @Autowired</span><br><span class="line">    private MqttClient mqttClient;</span><br><span class="line"></span><br><span class="line">    public void send(String payload) &#123;</span><br><span class="line">        this.send(defaultTopic, payload);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    public void send(String topic, String payload) &#123;</span><br><span class="line">        this.send(topic, defaultProducerQos, payload);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    public void send(String topic, int qos, String payload) &#123;</span><br><span class="line">        this.send(topic, qos, defaultRetained, payload);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    public void send(String topic, int qos, boolean retained, String payload) &#123;</span><br><span class="line">        try &#123;</span><br><span class="line">            mqttClient.publish(topic, payload.getBytes(), qos, retained);</span><br><span class="line">        &#125; catch (MqttException e) &#123;</span><br><span class="line">            System.out.println(e.getMessage());</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">@RestController</span><br><span class="line">public class MqttController &#123;</span><br><span class="line"></span><br><span class="line">    @Autowired</span><br><span class="line">    private MqttProducer mqttProducer;</span><br><span class="line"></span><br><span class="line">    @RequestMapping(&quot;/send&quot;)</span><br><span class="line">    public void send() &#123;</span><br><span class="line"></span><br><span class="line">        mqttProducer.send(&quot;test content&quot;);</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>完整代码：<a href="https://github.com/VictorBu/code-snippet/tree/master/java/mqtt-paho" target="_blank" rel="noopener">GitHub</a></p><blockquote><p>参考</p></blockquote><ol><li><a href="https://www.baeldung.com/java-mqtt-client" target="_blank" rel="noopener">MQTT Client in Java</a></li><li><a href="https://docs.emqx.io/broker/latest/cn/development/java.html" target="_blank" rel="noopener">MQTT Java 客户端库</a></li><li><a href="https://www.cnblogs.com/x-h-s/p/9455672.html" target="_blank" rel="noopener">使用paho的MQTT时遇到的重连导致订阅无法收到问题和解决</a></li></ol>]]></content>
    
    <summary type="html">
    
      
      
        &lt;blockquote&gt;
&lt;p&gt;Paho 自动重连后订阅的主题会清空，所以需要实现 MqttCallbackExtended 接口，在 connectComplete 方法添加订阅主题；而不是实现 MqttCallback 接口&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h1 id=
      
    
    </summary>
    
      <category term="IT" scheme="http://victor.karonda.com/categories/IT/"/>
    
    
      <category term="Java" scheme="http://victor.karonda.com/tags/Java/"/>
    
      <category term="MQTT" scheme="http://victor.karonda.com/tags/MQTT/"/>
    
      <category term="Paho" scheme="http://victor.karonda.com/tags/Paho/"/>
    
  </entry>
  
</feed>
